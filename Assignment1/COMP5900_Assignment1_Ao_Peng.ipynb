{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "COMP5900_Assignment1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "59ae701ee3bb4ece97c97934453f6ffe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_2b42f10f2cde4589be117773b594c95d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f528132fd68b4869b01cb5549b796e91",
              "IPY_MODEL_a02879265baf4476a76c067107dc922b"
            ]
          }
        },
        "2b42f10f2cde4589be117773b594c95d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f528132fd68b4869b01cb5549b796e91": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f0273decc8064cd585928e9a9d2b287e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_7e13d769d1854e6db2c7960948571c8e"
          }
        },
        "a02879265baf4476a76c067107dc922b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c4fe4ea1a504046a3249910abe8011b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170500096/? [00:05&lt;00:00, 31104143.46it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_41506cd8c45e409798f12d3fd458f4c4"
          }
        },
        "f0273decc8064cd585928e9a9d2b287e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "7e13d769d1854e6db2c7960948571c8e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c4fe4ea1a504046a3249910abe8011b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "41506cd8c45e409798f12d3fd458f4c4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tUjA0X_vURsr"
      },
      "source": [
        "#COMP5900 Assignment 1 (Supplementary Materials)\n",
        "Use this code to answer the questions in Assignment 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BMx0A0q6UHby",
        "outputId": "2b68213d-8206-40fe-d211-513886700ade"
      },
      "source": [
        "import torch\n",
        "print(torch.__version__)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.7.0+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "59ae701ee3bb4ece97c97934453f6ffe",
            "2b42f10f2cde4589be117773b594c95d",
            "f528132fd68b4869b01cb5549b796e91",
            "a02879265baf4476a76c067107dc922b",
            "f0273decc8064cd585928e9a9d2b287e",
            "7e13d769d1854e6db2c7960948571c8e",
            "1c4fe4ea1a504046a3249910abe8011b",
            "41506cd8c45e409798f12d3fd458f4c4"
          ]
        },
        "id": "B8E8pTxz4Smw",
        "outputId": "cc081e35-5c73-444e-ab64-7e536374876f"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "from torch.autograd import Variable\n",
        "torch.cuda.is_available()\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "59ae701ee3bb4ece97c97934453f6ffe",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F39JgDqw4mN3",
        "outputId": "4b08ce5e-980f-4373-9d25-d585c4928a18"
      },
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16 * 5 * \n",
        "                             , 120)\n",
        "        self.fc2 = nn.Linear(120, 120)\n",
        "        self.fc3 = nn.Linear(120, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16 * 5 * 5)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "print(Net())"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Net(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=120, bias=True)\n",
            "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zWhZxxla4rTv",
        "outputId": "4f1ca8fb-9840-4a9e-d001-5ddb5aa20450"
      },
      "source": [
        "import torch.optim as optim\n",
        "net=Net()\n",
        "CUDA=torch.cuda.is_available()\n",
        "if CUDA:\n",
        "  net=net.cuda()\n",
        "\n",
        "# Let's first define our device as the first visible cuda device if we have\n",
        "# CUDA available:  \n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Assuming that we are on a CUDA machine, this should print a CUDA device:\n",
        "print(device)\n",
        "\n",
        "#In Colab, got to Edit>Notebook settings> choose Python 3. For the hardware\n",
        "#accelerator, you may select None or GPU.\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3gYlmnOXJEPX",
        "outputId": "3b6dc6db-3a37-445d-ec32-ab7baf3fdaa7"
      },
      "source": [
        "# 4. Train the network\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "accuracy_values=[]\n",
        "epoch_number=[]\n",
        "for epoch in range(10):  # loop over the dataset multiple times. Here 10 means 10 epochs\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs,labels) in enumerate(trainloader, 0):\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        if CUDA:\n",
        "          inputs = inputs.cuda()\n",
        "          labels = labels.cuda()\n",
        "        else:\n",
        "          inputs = inputs.cpu()\n",
        "          labels = labels.cpu()        \n",
        "          \n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
        "            print('[epoch%d, itr%5d] loss: %.3f' %\n",
        "                  (epoch + 1, i + 1, running_loss / 2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            if CUDA:\n",
        "              images = images.cuda()\n",
        "              labels = labels.cuda()\n",
        "            else:\n",
        "              images = images.cpu()\n",
        "              labels =labels.cpu()\n",
        "\n",
        "            outputs = net(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            if not CUDA:\n",
        "              correct += (predicted.cpu()==labels.cpu()).sum().item()\n",
        "            else:\n",
        "              correct += (predicted==labels).sum().item()\n",
        "            \n",
        "        TestAccuracy = 100 * correct / total;\n",
        "        epoch_number += [epoch+1]\n",
        "        accuracy_values += [TestAccuracy] \n",
        "        print('Epoch=%d Test Accuracy=%.3f' %\n",
        "                  (epoch + 1, TestAccuracy))\n",
        "    \n",
        "print('Finished Training')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch1, itr 2000] loss: 2.174\n",
            "[epoch1, itr 4000] loss: 1.825\n",
            "[epoch1, itr 6000] loss: 1.651\n",
            "[epoch1, itr 8000] loss: 1.556\n",
            "[epoch1, itr10000] loss: 1.503\n",
            "[epoch1, itr12000] loss: 1.460\n",
            "Epoch=1 Test Accuracy=46.440\n",
            "[epoch2, itr 2000] loss: 1.387\n",
            "[epoch2, itr 4000] loss: 1.344\n",
            "[epoch2, itr 6000] loss: 1.327\n",
            "[epoch2, itr 8000] loss: 1.320\n",
            "[epoch2, itr10000] loss: 1.281\n",
            "[epoch2, itr12000] loss: 1.282\n",
            "Epoch=2 Test Accuracy=54.480\n",
            "[epoch3, itr 2000] loss: 1.203\n",
            "[epoch3, itr 4000] loss: 1.227\n",
            "[epoch3, itr 6000] loss: 1.188\n",
            "[epoch3, itr 8000] loss: 1.173\n",
            "[epoch3, itr10000] loss: 1.152\n",
            "[epoch3, itr12000] loss: 1.145\n",
            "Epoch=3 Test Accuracy=59.830\n",
            "[epoch4, itr 2000] loss: 1.089\n",
            "[epoch4, itr 4000] loss: 1.085\n",
            "[epoch4, itr 6000] loss: 1.083\n",
            "[epoch4, itr 8000] loss: 1.080\n",
            "[epoch4, itr10000] loss: 1.081\n",
            "[epoch4, itr12000] loss: 1.071\n",
            "Epoch=4 Test Accuracy=60.150\n",
            "[epoch5, itr 2000] loss: 1.009\n",
            "[epoch5, itr 4000] loss: 1.013\n",
            "[epoch5, itr 6000] loss: 1.032\n",
            "[epoch5, itr 8000] loss: 1.024\n",
            "[epoch5, itr10000] loss: 0.985\n",
            "[epoch5, itr12000] loss: 1.028\n",
            "Epoch=5 Test Accuracy=62.430\n",
            "[epoch6, itr 2000] loss: 0.932\n",
            "[epoch6, itr 4000] loss: 0.967\n",
            "[epoch6, itr 6000] loss: 0.935\n",
            "[epoch6, itr 8000] loss: 0.959\n",
            "[epoch6, itr10000] loss: 0.967\n",
            "[epoch6, itr12000] loss: 0.967\n",
            "Epoch=6 Test Accuracy=62.830\n",
            "[epoch7, itr 2000] loss: 0.849\n",
            "[epoch7, itr 4000] loss: 0.905\n",
            "[epoch7, itr 6000] loss: 0.908\n",
            "[epoch7, itr 8000] loss: 0.909\n",
            "[epoch7, itr10000] loss: 0.928\n",
            "[epoch7, itr12000] loss: 0.935\n",
            "Epoch=7 Test Accuracy=63.060\n",
            "[epoch8, itr 2000] loss: 0.832\n",
            "[epoch8, itr 4000] loss: 0.851\n",
            "[epoch8, itr 6000] loss: 0.857\n",
            "[epoch8, itr 8000] loss: 0.875\n",
            "[epoch8, itr10000] loss: 0.874\n",
            "[epoch8, itr12000] loss: 0.905\n",
            "Epoch=8 Test Accuracy=63.140\n",
            "[epoch9, itr 2000] loss: 0.796\n",
            "[epoch9, itr 4000] loss: 0.814\n",
            "[epoch9, itr 6000] loss: 0.814\n",
            "[epoch9, itr 8000] loss: 0.824\n",
            "[epoch9, itr10000] loss: 0.876\n",
            "[epoch9, itr12000] loss: 0.866\n",
            "Epoch=9 Test Accuracy=63.240\n",
            "[epoch10, itr 2000] loss: 0.756\n",
            "[epoch10, itr 4000] loss: 0.800\n",
            "[epoch10, itr 6000] loss: 0.813\n",
            "[epoch10, itr 8000] loss: 0.811\n",
            "[epoch10, itr10000] loss: 0.835\n",
            "[epoch10, itr12000] loss: 0.850\n",
            "Epoch=10 Test Accuracy=62.890\n",
            "Finished Training\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dh1qGFbTXkUb",
        "outputId": "9cd503ca-ab53-4bc5-f121-3a960bcbb7a8"
      },
      "source": [
        "print (torch.cuda.is_available())\n",
        "print (torch.cuda.device_count())"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n",
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nEIUWWLGv9ic",
        "outputId": "21bc9913-2a09-43e8-f8c3-8f26cf4c7849"
      },
      "source": [
        "epoch_number"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "5TRFTQ1eYt4g",
        "outputId": "84632cdb-2dde-4183-d293-51bf752ad00a"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(accuracy_values)\n",
        "# Plot the data\n",
        "plt.plot(epoch_number, accuracy_values, label='CNN')\n",
        "\n",
        "# Add a legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "## Anything better than 10% accuracy (randomly picking a class out of 10 classes)\n",
        "# means the network has learned something."
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[46.44, 54.48, 59.83, 60.15, 62.43, 62.83, 63.06, 63.14, 63.24, 62.89]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2nHrRZNRkD_"
      },
      "source": [
        "Network with 0 hidden layer\n",
        "\n",
        "Question: \n",
        "1. Pooling layer belongs to hidden layer or not?\n",
        "2. What is the size of the input data? [4 * 3 * 32 *32]\n",
        "3. What is the meaning of each number?\n",
        "4. Why I cannot use the dimension with (4 * 3 * 32 * 32, 10) in a FC layer?\n",
        "5. Why there is no activation function?\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4dohqhoXRjm4",
        "outputId": "d07faeeb-eb0a-4ee5-fabb-f5d01ae39955"
      },
      "source": [
        "class Net_without_hidden_layer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_without_hidden_layer, self).__init__()\n",
        "        # self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(3*32*32, 10)\n",
        "        \n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.pool(x)\n",
        "        # print(\"1 and {0}\".format(x.size()))\n",
        "        x = x.view(-1, 3*32*32)\n",
        "        # print(\"2 and {0}\".format(x.size()))\n",
        "        x = self.fc1(x)\n",
        "        return x\n",
        "print(Net_without_hidden_layer())"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net_without_hidden_layer(\n",
            "  (fc1): Linear(in_features=3072, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VkV8YPDxLOB"
      },
      "source": [
        "net_no_h = Net_without_hidden_layer()\n",
        "if CUDA:\n",
        "  net_no_h = net_no_h.cuda()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jwxueLamOe-X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b6be9a26-e68f-4cff-b2b6-8e9e3c3d9479"
      },
      "source": [
        "# Training step\n",
        "# criterion = nn.CrossEntropyLoss\n",
        "# optimizer = optim.SGD(net.parameters(), lr=0.001, momentum=0.9)\n",
        "accuracy_values_without_h = []\n",
        "\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs,labels) in enumerate(trainloader, 0):\n",
        "      # get the inputs; data is a list of [inputs, labels]\n",
        "      if CUDA:\n",
        "        inputs = inputs.cuda()\n",
        "        labels = labels.cuda()\n",
        "      else:\n",
        "        inputs = inputs.cpu()\n",
        "        labels = labels.cpu() \n",
        "      if i == 0:\n",
        "        print(inputs.size())\n",
        "        print(labels.size())\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "      # print(\"input_size={0}\".format(inputs.size()))\n",
        "      outputs = net_no_h(inputs)\n",
        "      # print(\"outputs_size={0}\".format(outputs.size()))\n",
        "      # print(\"labels_size={0}\".format(labels.size()))\n",
        "      # print(torch.squeeze(labels).long().size())\n",
        "      loss = criterion(outputs, labels)\n",
        "      loss.backward()\n",
        "      optimizer.step() # how optimizer works?\n",
        "\n",
        "      running_loss += loss.item()\n",
        "      if i % 2000 == 1999:\n",
        "          print('[epoch%d, itr%5d] loss: %.3f' %\n",
        "              ( epoch + 1, i + 1, running_loss / 2000))\n",
        "          running_loss = 0.0\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            if CUDA:\n",
        "              images = images.cuda()\n",
        "              labels = labels.cuda()\n",
        "            else:\n",
        "              images = images.cuda()\n",
        "              labels = labels.cuda()\n",
        "\n",
        "            outputs = net_no_h(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            if not CUDA:\n",
        "              correct += (predicted.cpu() == labels.cpu()).sum().item()\n",
        "            else:\n",
        "              correct += (predicted == labels).sum().item()\n",
        "\n",
        "        TestAccuracy = 100 * correct / total\n",
        "        accuracy_values_without_h += [TestAccuracy]\n",
        "        print('Epoch=%d Test Accracy=%.3f' %(epoch+1, TestAccuracy))\n",
        "\n",
        "print('Finish Training (0 hidden layer)')\n",
        "\n"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([4, 3, 32, 32])\n",
            "torch.Size([4])\n",
            "[epoch1, itr 2000] loss: 2.396\n",
            "[epoch1, itr 4000] loss: 2.390\n",
            "[epoch1, itr 6000] loss: 2.396\n",
            "[epoch1, itr 8000] loss: 2.394\n",
            "[epoch1, itr10000] loss: 2.392\n",
            "[epoch1, itr12000] loss: 2.402\n",
            "Epoch=1 Test Accracy=7.200\n",
            "torch.Size([4, 3, 32, 32])\n",
            "torch.Size([4])\n",
            "[epoch2, itr 2000] loss: 2.398\n",
            "[epoch2, itr 4000] loss: 2.397\n",
            "[epoch2, itr 6000] loss: 2.395\n",
            "[epoch2, itr 8000] loss: 2.395\n",
            "[epoch2, itr10000] loss: 2.395\n",
            "[epoch2, itr12000] loss: 2.394\n",
            "Epoch=2 Test Accracy=7.200\n",
            "torch.Size([4, 3, 32, 32])\n",
            "torch.Size([4])\n",
            "[epoch3, itr 2000] loss: 2.395\n",
            "[epoch3, itr 4000] loss: 2.396\n",
            "[epoch3, itr 6000] loss: 2.395\n",
            "[epoch3, itr 8000] loss: 2.394\n",
            "[epoch3, itr10000] loss: 2.396\n",
            "[epoch3, itr12000] loss: 2.395\n",
            "Epoch=3 Test Accracy=7.200\n",
            "torch.Size([4, 3, 32, 32])\n",
            "torch.Size([4])\n",
            "[epoch4, itr 2000] loss: 2.395\n",
            "[epoch4, itr 4000] loss: 2.398\n",
            "[epoch4, itr 6000] loss: 2.396\n",
            "[epoch4, itr 8000] loss: 2.390\n",
            "[epoch4, itr10000] loss: 2.401\n",
            "[epoch4, itr12000] loss: 2.391\n",
            "Epoch=4 Test Accracy=7.200\n",
            "torch.Size([4, 3, 32, 32])\n",
            "torch.Size([4])\n",
            "[epoch5, itr 2000] loss: 2.392\n",
            "[epoch5, itr 4000] loss: 2.398\n",
            "[epoch5, itr 6000] loss: 2.393\n",
            "[epoch5, itr 8000] loss: 2.396\n",
            "[epoch5, itr10000] loss: 2.394\n",
            "[epoch5, itr12000] loss: 2.398\n",
            "Epoch=5 Test Accracy=7.200\n",
            "torch.Size([4, 3, 32, 32])\n",
            "torch.Size([4])\n",
            "[epoch6, itr 2000] loss: 2.391\n",
            "[epoch6, itr 4000] loss: 2.394\n",
            "[epoch6, itr 6000] loss: 2.397\n",
            "[epoch6, itr 8000] loss: 2.394\n",
            "[epoch6, itr10000] loss: 2.401\n",
            "[epoch6, itr12000] loss: 2.395\n",
            "Epoch=6 Test Accracy=7.200\n",
            "torch.Size([4, 3, 32, 32])\n",
            "torch.Size([4])\n",
            "[epoch7, itr 2000] loss: 2.393\n",
            "[epoch7, itr 4000] loss: 2.395\n",
            "[epoch7, itr 6000] loss: 2.396\n",
            "[epoch7, itr 8000] loss: 2.402\n",
            "[epoch7, itr10000] loss: 2.392\n",
            "[epoch7, itr12000] loss: 2.392\n",
            "Epoch=7 Test Accracy=7.200\n",
            "torch.Size([4, 3, 32, 32])\n",
            "torch.Size([4])\n",
            "[epoch8, itr 2000] loss: 2.393\n",
            "[epoch8, itr 4000] loss: 2.392\n",
            "[epoch8, itr 6000] loss: 2.395\n",
            "[epoch8, itr 8000] loss: 2.399\n",
            "[epoch8, itr10000] loss: 2.394\n",
            "[epoch8, itr12000] loss: 2.399\n",
            "Epoch=8 Test Accracy=7.200\n",
            "torch.Size([4, 3, 32, 32])\n",
            "torch.Size([4])\n",
            "[epoch9, itr 2000] loss: 2.397\n",
            "[epoch9, itr 4000] loss: 2.397\n",
            "[epoch9, itr 6000] loss: 2.393\n",
            "[epoch9, itr 8000] loss: 2.395\n",
            "[epoch9, itr10000] loss: 2.395\n",
            "[epoch9, itr12000] loss: 2.394\n",
            "Epoch=9 Test Accracy=7.200\n",
            "torch.Size([4, 3, 32, 32])\n",
            "torch.Size([4])\n",
            "[epoch10, itr 2000] loss: 2.394\n",
            "[epoch10, itr 4000] loss: 2.398\n",
            "[epoch10, itr 6000] loss: 2.402\n",
            "[epoch10, itr 8000] loss: 2.397\n",
            "[epoch10, itr10000] loss: 2.389\n",
            "[epoch10, itr12000] loss: 2.392\n",
            "Epoch=10 Test Accracy=7.200\n",
            "Finish Training (0 hidden layer)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ctZTpRhSSIwY"
      },
      "source": [
        "Network with 1 hidden layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fn1lNF9lSINC",
        "outputId": "c1999a5d-a306-4b70-b47d-a01c397c33e1"
      },
      "source": [
        "class Net_with_one_hidden_layer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_with_one_hidden_layer, self).__init__()\n",
        "        # self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(3*32*32, 120)\n",
        "        self.fc2 = nn.Linear(120, 10)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.pool(x)\n",
        "        x = x.view(-1, 3*32*32) # I think it is to flatten the image to 1 dimension\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "print(Net_with_one_hidden_layer())"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net_with_one_hidden_layer(\n",
            "  (fc1): Linear(in_features=3072, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x-bhlYb7RUrb"
      },
      "source": [
        "net_with_1_h = Net_with_one_hidden_layer()\n",
        "if CUDA:\n",
        "    net_with_1_h = net_with_1_h.cuda()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEAWoYiHRU7B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "104a7e98-abd1-46b3-e291-05d49bfc0e1d"
      },
      "source": [
        "# Training with 1 hidden layers\n",
        "# criterion is Cross Entropy loss\n",
        "# optimizer is SGD\n",
        "\n",
        "accuracy_values_1_h = []\n",
        "\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "        if CUDA:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        else:\n",
        "            inputs = inputs.cpu()\n",
        "            labels = labels.cpu()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net_with_1_h(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:\n",
        "            print('[epoch%d, itr%5d] loss: %.3f' % (epoch+1, i+1, running_loss/2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for image, labels in testloader:\n",
        "            count += 1\n",
        "            if CUDA:\n",
        "              images = images.cuda()\n",
        "              labels = labels.cuda()\n",
        "            else:\n",
        "              images = images.cpu()\n",
        "              labels =labels.cpu()\n",
        "            \n",
        "            outputs = net_with_1_h(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            if not CUDA:\n",
        "              correct += (predicted.cpu()==labels.cpu()).sum().item()\n",
        "            else:\n",
        "              correct += (predicted==labels).sum().item()\n",
        "          \n",
        "        TestAccuracy = 100 * correct / total\n",
        "        accuracy_values_1_h += [TestAccuracy]\n",
        "        print('Epoch=%d Test Accuracy=%.3f' % (epoch+1, TestAccuracy))\n",
        "\n",
        "print('Finished Training with 1 hidden layer')\n",
        "  "
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch1, itr 2000] loss: 2.312\n",
            "[epoch1, itr 4000] loss: 2.311\n",
            "[epoch1, itr 6000] loss: 2.312\n",
            "[epoch1, itr 8000] loss: 2.314\n",
            "[epoch1, itr10000] loss: 2.315\n",
            "[epoch1, itr12000] loss: 2.313\n",
            "1\n",
            "4\n",
            "2\n",
            "4\n",
            "Epoch=1 Test Accuracy=10.290\n",
            "[epoch2, itr 2000] loss: 2.312\n",
            "[epoch2, itr 4000] loss: 2.313\n",
            "[epoch2, itr 6000] loss: 2.311\n",
            "[epoch2, itr 8000] loss: 2.316\n",
            "[epoch2, itr10000] loss: 2.311\n",
            "[epoch2, itr12000] loss: 2.314\n",
            "1\n",
            "4\n",
            "2\n",
            "4\n",
            "Epoch=2 Test Accuracy=10.290\n",
            "[epoch3, itr 2000] loss: 2.314\n",
            "[epoch3, itr 4000] loss: 2.312\n",
            "[epoch3, itr 6000] loss: 2.314\n",
            "[epoch3, itr 8000] loss: 2.315\n",
            "[epoch3, itr10000] loss: 2.310\n",
            "[epoch3, itr12000] loss: 2.312\n",
            "1\n",
            "4\n",
            "2\n",
            "4\n",
            "Epoch=3 Test Accuracy=10.290\n",
            "[epoch4, itr 2000] loss: 2.312\n",
            "[epoch4, itr 4000] loss: 2.311\n",
            "[epoch4, itr 6000] loss: 2.312\n",
            "[epoch4, itr 8000] loss: 2.311\n",
            "[epoch4, itr10000] loss: 2.314\n",
            "[epoch4, itr12000] loss: 2.316\n",
            "1\n",
            "4\n",
            "2\n",
            "4\n",
            "Epoch=4 Test Accuracy=10.290\n",
            "[epoch5, itr 2000] loss: 2.314\n",
            "[epoch5, itr 4000] loss: 2.314\n",
            "[epoch5, itr 6000] loss: 2.311\n",
            "[epoch5, itr 8000] loss: 2.314\n",
            "[epoch5, itr10000] loss: 2.312\n",
            "[epoch5, itr12000] loss: 2.313\n",
            "1\n",
            "4\n",
            "2\n",
            "4\n",
            "Epoch=5 Test Accuracy=10.290\n",
            "[epoch6, itr 2000] loss: 2.311\n",
            "[epoch6, itr 4000] loss: 2.312\n",
            "[epoch6, itr 6000] loss: 2.314\n",
            "[epoch6, itr 8000] loss: 2.314\n",
            "[epoch6, itr10000] loss: 2.315\n",
            "[epoch6, itr12000] loss: 2.312\n",
            "1\n",
            "4\n",
            "2\n",
            "4\n",
            "Epoch=6 Test Accuracy=10.290\n",
            "[epoch7, itr 2000] loss: 2.311\n",
            "[epoch7, itr 4000] loss: 2.312\n",
            "[epoch7, itr 6000] loss: 2.313\n",
            "[epoch7, itr 8000] loss: 2.312\n",
            "[epoch7, itr10000] loss: 2.313\n",
            "[epoch7, itr12000] loss: 2.315\n",
            "1\n",
            "4\n",
            "2\n",
            "4\n",
            "Epoch=7 Test Accuracy=10.290\n",
            "[epoch8, itr 2000] loss: 2.311\n",
            "[epoch8, itr 4000] loss: 2.313\n",
            "[epoch8, itr 6000] loss: 2.312\n",
            "[epoch8, itr 8000] loss: 2.314\n",
            "[epoch8, itr10000] loss: 2.314\n",
            "[epoch8, itr12000] loss: 2.312\n",
            "1\n",
            "4\n",
            "2\n",
            "4\n",
            "Epoch=8 Test Accuracy=10.290\n",
            "[epoch9, itr 2000] loss: 2.311\n",
            "[epoch9, itr 4000] loss: 2.312\n",
            "[epoch9, itr 6000] loss: 2.313\n",
            "[epoch9, itr 8000] loss: 2.316\n",
            "[epoch9, itr10000] loss: 2.311\n",
            "[epoch9, itr12000] loss: 2.313\n",
            "1\n",
            "4\n",
            "2\n",
            "4\n",
            "Epoch=9 Test Accuracy=10.290\n",
            "[epoch10, itr 2000] loss: 2.311\n",
            "[epoch10, itr 4000] loss: 2.312\n",
            "[epoch10, itr 6000] loss: 2.315\n",
            "[epoch10, itr 8000] loss: 2.312\n",
            "[epoch10, itr10000] loss: 2.311\n",
            "[epoch10, itr12000] loss: 2.315\n",
            "1\n",
            "4\n",
            "2\n",
            "4\n",
            "Epoch=10 Test Accuracy=10.290\n",
            "Finished Training with 1 hidden layer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W9q69MUMTNf5"
      },
      "source": [
        "Newwork with 2 hidden layers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "joGRppLZTRUM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce1300eb-7ccd-4376-edd3-14af93de1d06"
      },
      "source": [
        "class Net_with_two_hidden_layer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_with_two_hidden_layer, self).__init__()\n",
        "        # self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(3*32*32, 120)\n",
        "        self.fc2 = nn.Linear(120, 120)\n",
        "        self.fc3 = nn.Linear(120, 10)\n",
        "      \n",
        "\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.pool(x)\n",
        "        x = x.view(-1, 3*32*32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "print(Net_with_two_hidden_layer())"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net_with_two_hidden_layer(\n",
            "  (fc1): Linear(in_features=3072, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=120, bias=True)\n",
            "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l7RLxh4sMGVC"
      },
      "source": [
        "net_with_2_h = Net_with_two_hidden_layer()\n",
        "if CUDA:\n",
        "  net_with_2_h = net_with_2_h.cuda()\n",
        "  "
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSZYijeZJ2Hs",
        "outputId": "ebc3524e-aed5-4fe6-8405-3cbd42bba61f"
      },
      "source": [
        "# Training with 2 hidden layers\n",
        "# criterion is Cross Entropy loss\n",
        "# optimizer is SGD\n",
        "\n",
        "accuracy_values_2_h = []\n",
        "\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "        if CUDA:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        else:\n",
        "            inputs = inputs.cpu()\n",
        "            labels = labels.cpu()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net_with_2_h(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:\n",
        "            print('[epoch%d, itr%5d] loss: %.3f' % (epoch+1, i+1, running_loss/2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for image, labels in testloader:\n",
        "            count += 1\n",
        "            if CUDA:\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "            else:\n",
        "                images = images.cpu()\n",
        "                labels =labels.cpu()\n",
        "            \n",
        "            outputs = net_with_2_h(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            if not CUDA:\n",
        "                correct += (predicted.cpu()==labels.cpu()).sum().item()\n",
        "            else:\n",
        "                correct += (predicted==labels).sum().item()\n",
        "        \n",
        "        TestAccuracy = 100 * correct / total\n",
        "        accuracy_values_2_h += [TestAccuracy]\n",
        "        print('Epoch=%d Test Accuracy=%.3f' % (epoch+1, TestAccuracy))\n",
        "\n",
        "print('Finished Training with 2 hidden layer')\n",
        "  "
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch1, itr 2000] loss: 2.307\n",
            "[epoch1, itr 4000] loss: 2.306\n",
            "[epoch1, itr 6000] loss: 2.307\n",
            "[epoch1, itr 8000] loss: 2.307\n",
            "[epoch1, itr10000] loss: 2.307\n",
            "[epoch1, itr12000] loss: 2.306\n",
            "Epoch=1 Test Accuracy=10.000\n",
            "[epoch2, itr 2000] loss: 2.307\n",
            "[epoch2, itr 4000] loss: 2.308\n",
            "[epoch2, itr 6000] loss: 2.307\n",
            "[epoch2, itr 8000] loss: 2.306\n",
            "[epoch2, itr10000] loss: 2.306\n",
            "[epoch2, itr12000] loss: 2.308\n",
            "Epoch=2 Test Accuracy=10.000\n",
            "[epoch3, itr 2000] loss: 2.307\n",
            "[epoch3, itr 4000] loss: 2.307\n",
            "[epoch3, itr 6000] loss: 2.307\n",
            "[epoch3, itr 8000] loss: 2.306\n",
            "[epoch3, itr10000] loss: 2.307\n",
            "[epoch3, itr12000] loss: 2.307\n",
            "Epoch=3 Test Accuracy=10.000\n",
            "[epoch4, itr 2000] loss: 2.307\n",
            "[epoch4, itr 4000] loss: 2.307\n",
            "[epoch4, itr 6000] loss: 2.306\n",
            "[epoch4, itr 8000] loss: 2.307\n",
            "[epoch4, itr10000] loss: 2.306\n",
            "[epoch4, itr12000] loss: 2.307\n",
            "Epoch=4 Test Accuracy=10.000\n",
            "[epoch5, itr 2000] loss: 2.306\n",
            "[epoch5, itr 4000] loss: 2.308\n",
            "[epoch5, itr 6000] loss: 2.307\n",
            "[epoch5, itr 8000] loss: 2.307\n",
            "[epoch5, itr10000] loss: 2.307\n",
            "[epoch5, itr12000] loss: 2.305\n",
            "Epoch=5 Test Accuracy=10.000\n",
            "[epoch6, itr 2000] loss: 2.308\n",
            "[epoch6, itr 4000] loss: 2.306\n",
            "[epoch6, itr 6000] loss: 2.307\n",
            "[epoch6, itr 8000] loss: 2.306\n",
            "[epoch6, itr10000] loss: 2.307\n",
            "[epoch6, itr12000] loss: 2.307\n",
            "Epoch=6 Test Accuracy=10.000\n",
            "[epoch7, itr 2000] loss: 2.307\n",
            "[epoch7, itr 4000] loss: 2.306\n",
            "[epoch7, itr 6000] loss: 2.307\n",
            "[epoch7, itr 8000] loss: 2.307\n",
            "[epoch7, itr10000] loss: 2.307\n",
            "[epoch7, itr12000] loss: 2.307\n",
            "Epoch=7 Test Accuracy=10.000\n",
            "[epoch8, itr 2000] loss: 2.307\n",
            "[epoch8, itr 4000] loss: 2.308\n",
            "[epoch8, itr 6000] loss: 2.307\n",
            "[epoch8, itr 8000] loss: 2.306\n",
            "[epoch8, itr10000] loss: 2.306\n",
            "[epoch8, itr12000] loss: 2.307\n",
            "Epoch=8 Test Accuracy=10.000\n",
            "[epoch9, itr 2000] loss: 2.307\n",
            "[epoch9, itr 4000] loss: 2.307\n",
            "[epoch9, itr 6000] loss: 2.307\n",
            "[epoch9, itr 8000] loss: 2.307\n",
            "[epoch9, itr10000] loss: 2.306\n",
            "[epoch9, itr12000] loss: 2.307\n",
            "Epoch=9 Test Accuracy=10.000\n",
            "[epoch10, itr 2000] loss: 2.307\n",
            "[epoch10, itr 4000] loss: 2.307\n",
            "[epoch10, itr 6000] loss: 2.307\n",
            "[epoch10, itr 8000] loss: 2.306\n",
            "[epoch10, itr10000] loss: 2.306\n",
            "[epoch10, itr12000] loss: 2.307\n",
            "Epoch=10 Test Accuracy=10.000\n",
            "Finished Training with 2 hidden layer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6P89oYYUT_4s"
      },
      "source": [
        "Newwork with 3 hidden layers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x0m6pL5MT_4u",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16b79aba-aef7-44e1-fb63-09e616bd21e3"
      },
      "source": [
        "class Net_with_three_hidden_layer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_with_three_hidden_layer, self).__init__()\n",
        "        # self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(3*32*32, 120)\n",
        "        self.fc2 = nn.Linear(120, 120)\n",
        "        self.fc3 = nn.Linear(120, 120)\n",
        "        self.fc4 = nn.Linear(120, 10)\n",
        "\n",
        "      \n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.pool(x)\n",
        "        x = x.view(-1, 3*32*32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = self.fc4(x)\n",
        "        return x\n",
        "print(Net_with_three_hidden_layer())"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net_with_three_hidden_layer(\n",
            "  (fc1): Linear(in_features=3072, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=120, bias=True)\n",
            "  (fc3): Linear(in_features=120, out_features=120, bias=True)\n",
            "  (fc4): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1UjYPe4Rou6"
      },
      "source": [
        "net_with_3_h = Net_with_three_hidden_layer()\n",
        "if CUDA:\n",
        "  net_with_3_h = net_with_3_h.cuda()"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P1fLM0OkRo99",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "30e53b67-1222-4534-917f-65dd9055d658"
      },
      "source": [
        "# Training with 3 hidden layers\n",
        "# criterion is Cross Entropy loss\n",
        "# optimizer is SGD\n",
        "\n",
        "accuracy_values_3_h = []\n",
        "\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "        if CUDA:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        else:\n",
        "            inputs = inputs.cpu()\n",
        "            labels = labels.cpu()\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        outputs = net_with_3_h(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:\n",
        "          print('[epoch%d, itr%5d] loss: %.3f' % (epoch+1, i+1, running_loss/2000))\n",
        "          running_loss = 0.0\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    count = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            count += 1\n",
        "            if CUDA:\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "            else:\n",
        "                images = images.cpu()\n",
        "                labels =labels.cpu()\n",
        "            \n",
        "            outputs = net_with_3_h(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            if not CUDA:\n",
        "                correct += (predicted.cpu()==labels.cpu()).sum().item()\n",
        "            else:\n",
        "                correct += (predicted==labels).sum().item()\n",
        "        \n",
        "        TestAccuracy = 100 * correct / total\n",
        "        accuracy_values_3_h += [TestAccuracy]\n",
        "        print('Epoch=%d Test Accuracy=%.3f' % (epoch+1, TestAccuracy))\n",
        "\n",
        "print('Finished Training with 3 hidden layer')\n",
        "  "
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch1, itr 2000] loss: 2.302\n",
            "[epoch1, itr 4000] loss: 2.303\n",
            "[epoch1, itr 6000] loss: 2.302\n",
            "[epoch1, itr 8000] loss: 2.301\n",
            "[epoch1, itr10000] loss: 2.302\n",
            "[epoch1, itr12000] loss: 2.302\n",
            "Epoch=1 Test Accuracy=11.500\n",
            "[epoch2, itr 2000] loss: 2.302\n",
            "[epoch2, itr 4000] loss: 2.302\n",
            "[epoch2, itr 6000] loss: 2.302\n",
            "[epoch2, itr 8000] loss: 2.302\n",
            "[epoch2, itr10000] loss: 2.302\n",
            "[epoch2, itr12000] loss: 2.302\n",
            "Epoch=2 Test Accuracy=11.500\n",
            "[epoch3, itr 2000] loss: 2.303\n",
            "[epoch3, itr 4000] loss: 2.302\n",
            "[epoch3, itr 6000] loss: 2.303\n",
            "[epoch3, itr 8000] loss: 2.301\n",
            "[epoch3, itr10000] loss: 2.303\n",
            "[epoch3, itr12000] loss: 2.302\n",
            "Epoch=3 Test Accuracy=11.500\n",
            "[epoch4, itr 2000] loss: 2.303\n",
            "[epoch4, itr 4000] loss: 2.302\n",
            "[epoch4, itr 6000] loss: 2.302\n",
            "[epoch4, itr 8000] loss: 2.302\n",
            "[epoch4, itr10000] loss: 2.302\n",
            "[epoch4, itr12000] loss: 2.303\n",
            "Epoch=4 Test Accuracy=11.500\n",
            "[epoch5, itr 2000] loss: 2.302\n",
            "[epoch5, itr 4000] loss: 2.303\n",
            "[epoch5, itr 6000] loss: 2.302\n",
            "[epoch5, itr 8000] loss: 2.301\n",
            "[epoch5, itr10000] loss: 2.302\n",
            "[epoch5, itr12000] loss: 2.302\n",
            "Epoch=5 Test Accuracy=11.500\n",
            "[epoch6, itr 2000] loss: 2.303\n",
            "[epoch6, itr 4000] loss: 2.302\n",
            "[epoch6, itr 6000] loss: 2.302\n",
            "[epoch6, itr 8000] loss: 2.302\n",
            "[epoch6, itr10000] loss: 2.303\n",
            "[epoch6, itr12000] loss: 2.303\n",
            "Epoch=6 Test Accuracy=11.500\n",
            "[epoch7, itr 2000] loss: 2.302\n",
            "[epoch7, itr 4000] loss: 2.302\n",
            "[epoch7, itr 6000] loss: 2.302\n",
            "[epoch7, itr 8000] loss: 2.302\n",
            "[epoch7, itr10000] loss: 2.302\n",
            "[epoch7, itr12000] loss: 2.302\n",
            "Epoch=7 Test Accuracy=11.500\n",
            "[epoch8, itr 2000] loss: 2.303\n",
            "[epoch8, itr 4000] loss: 2.302\n",
            "[epoch8, itr 6000] loss: 2.302\n",
            "[epoch8, itr 8000] loss: 2.302\n",
            "[epoch8, itr10000] loss: 2.302\n",
            "[epoch8, itr12000] loss: 2.303\n",
            "Epoch=8 Test Accuracy=11.500\n",
            "[epoch9, itr 2000] loss: 2.303\n",
            "[epoch9, itr 4000] loss: 2.303\n",
            "[epoch9, itr 6000] loss: 2.302\n",
            "[epoch9, itr 8000] loss: 2.303\n",
            "[epoch9, itr10000] loss: 2.302\n",
            "[epoch9, itr12000] loss: 2.302\n",
            "Epoch=9 Test Accuracy=11.500\n",
            "[epoch10, itr 2000] loss: 2.302\n",
            "[epoch10, itr 4000] loss: 2.302\n",
            "[epoch10, itr 6000] loss: 2.303\n",
            "[epoch10, itr 8000] loss: 2.301\n",
            "[epoch10, itr10000] loss: 2.302\n",
            "[epoch10, itr12000] loss: 2.303\n",
            "Epoch=10 Test Accuracy=11.500\n",
            "Finished Training with 3 hidden layer\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0akzlxfQUMkM"
      },
      "source": [
        "Newwork with 4 hidden layers\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oJ5RyPEwUMkM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d168ddd4-58bf-47a2-8101-e9b1a36cd41d"
      },
      "source": [
        "class Net_with_four_hidden_layer(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_with_four_hidden_layer, self).__init__()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.fc1 = nn.Linear(3*32*32, 120)\n",
        "        self.fc2 = nn.Linear(120, 120)\n",
        "        self.fc3 = nn.Linear(120, 120)\n",
        "        self.fc4 = nn.Linear(120, 120)\n",
        "        self.fc5 = nn.Linear(120, 10)\n",
        "      \n",
        "\n",
        "    def forward(self, x):\n",
        "        # x = self.pool(x)\n",
        "        x = x.view(-1, 3*32*32)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = F.relu(self.fc3(x))\n",
        "        x = F.relu(self.fc4(x))\n",
        "        x = self.fc5(x)\n",
        "        return x\n",
        "print(Net_with_four_hidden_layer())"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net_with_four_hidden_layer(\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=3072, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=120, bias=True)\n",
            "  (fc3): Linear(in_features=120, out_features=120, bias=True)\n",
            "  (fc4): Linear(in_features=120, out_features=120, bias=True)\n",
            "  (fc5): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_v6uDqhMR2Zk"
      },
      "source": [
        "net_with_4_h = Net_with_four_hidden_layer()\n",
        "if CUDA:\n",
        "  net_with_4_h = net_with_4_h.cuda()"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wqTbqgLeR2pN",
        "outputId": "a5c32db1-bb67-4a81-b3cb-c9bf2be89c89"
      },
      "source": [
        "# Training with 4 hidden layers\n",
        "# criterion is Cross Entropy loss\n",
        "# optimizer is SGD\n",
        "accuracy_values_4_h = []\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        if CUDA:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        else:\n",
        "            inputs = inputs.cpu()\n",
        "            labels = labels.cpu()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net_with_4_h(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:\n",
        "            print('[epoch%d, itr%5d] loss: %.3f' %\n",
        "                  (epoch+1, i+1, running_loss/2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            if CUDA:\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "            else:\n",
        "                images = images.cpu()\n",
        "                labels = labels.cpu()\n",
        "\n",
        "            outputs = net_with_4_h(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            if not CUDA:\n",
        "                correct += (predicted.cpu() == labels.cpu()).sum().item()\n",
        "            else:\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        TextAccuracy = 100 * correct / total\n",
        "        accuracy_values_4_h += [TextAccuracy]\n",
        "        print('Epoch=%d Test Accuracy=%.3f' %\n",
        "              (epoch+1, TextAccuracy))\n",
        "      \n",
        "print('Finished Training with 4 hidden layers')\n",
        "\n"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch1, itr 2000] loss: 2.304\n",
            "[epoch1, itr 4000] loss: 2.305\n",
            "[epoch1, itr 6000] loss: 2.304\n",
            "[epoch1, itr 8000] loss: 2.305\n",
            "[epoch1, itr10000] loss: 2.304\n",
            "[epoch1, itr12000] loss: 2.304\n",
            "Epoch=1 Test Accuracy=11.310\n",
            "[epoch2, itr 2000] loss: 2.305\n",
            "[epoch2, itr 4000] loss: 2.305\n",
            "[epoch2, itr 6000] loss: 2.304\n",
            "[epoch2, itr 8000] loss: 2.304\n",
            "[epoch2, itr10000] loss: 2.303\n",
            "[epoch2, itr12000] loss: 2.304\n",
            "Epoch=2 Test Accuracy=11.310\n",
            "[epoch3, itr 2000] loss: 2.305\n",
            "[epoch3, itr 4000] loss: 2.304\n",
            "[epoch3, itr 6000] loss: 2.304\n",
            "[epoch3, itr 8000] loss: 2.304\n",
            "[epoch3, itr10000] loss: 2.304\n",
            "[epoch3, itr12000] loss: 2.305\n",
            "Epoch=3 Test Accuracy=11.310\n",
            "[epoch4, itr 2000] loss: 2.305\n",
            "[epoch4, itr 4000] loss: 2.303\n",
            "[epoch4, itr 6000] loss: 2.305\n",
            "[epoch4, itr 8000] loss: 2.303\n",
            "[epoch4, itr10000] loss: 2.305\n",
            "[epoch4, itr12000] loss: 2.305\n",
            "Epoch=4 Test Accuracy=11.310\n",
            "[epoch5, itr 2000] loss: 2.304\n",
            "[epoch5, itr 4000] loss: 2.305\n",
            "[epoch5, itr 6000] loss: 2.304\n",
            "[epoch5, itr 8000] loss: 2.304\n",
            "[epoch5, itr10000] loss: 2.304\n",
            "[epoch5, itr12000] loss: 2.304\n",
            "Epoch=5 Test Accuracy=11.310\n",
            "[epoch6, itr 2000] loss: 2.303\n",
            "[epoch6, itr 4000] loss: 2.305\n",
            "[epoch6, itr 6000] loss: 2.304\n",
            "[epoch6, itr 8000] loss: 2.304\n",
            "[epoch6, itr10000] loss: 2.305\n",
            "[epoch6, itr12000] loss: 2.304\n",
            "Epoch=6 Test Accuracy=11.310\n",
            "[epoch7, itr 2000] loss: 2.304\n",
            "[epoch7, itr 4000] loss: 2.304\n",
            "[epoch7, itr 6000] loss: 2.304\n",
            "[epoch7, itr 8000] loss: 2.305\n",
            "[epoch7, itr10000] loss: 2.304\n",
            "[epoch7, itr12000] loss: 2.304\n",
            "Epoch=7 Test Accuracy=11.310\n",
            "[epoch8, itr 2000] loss: 2.305\n",
            "[epoch8, itr 4000] loss: 2.304\n",
            "[epoch8, itr 6000] loss: 2.306\n",
            "[epoch8, itr 8000] loss: 2.303\n",
            "[epoch8, itr10000] loss: 2.304\n",
            "[epoch8, itr12000] loss: 2.304\n",
            "Epoch=8 Test Accuracy=11.310\n",
            "[epoch9, itr 2000] loss: 2.304\n",
            "[epoch9, itr 4000] loss: 2.305\n",
            "[epoch9, itr 6000] loss: 2.303\n",
            "[epoch9, itr 8000] loss: 2.304\n",
            "[epoch9, itr10000] loss: 2.305\n",
            "[epoch9, itr12000] loss: 2.304\n",
            "Epoch=9 Test Accuracy=11.310\n",
            "[epoch10, itr 2000] loss: 2.304\n",
            "[epoch10, itr 4000] loss: 2.304\n",
            "[epoch10, itr 6000] loss: 2.304\n",
            "[epoch10, itr 8000] loss: 2.304\n",
            "[epoch10, itr10000] loss: 2.304\n",
            "[epoch10, itr12000] loss: 2.305\n",
            "Epoch=10 Test Accuracy=11.310\n",
            "Finished Training with 4 hidden layers\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "wla05HbQMgn3",
        "outputId": "3da624ba-cd4b-434a-9371-bea3614dffdf"
      },
      "source": [
        "# test plots\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\"Base model: {0}\".format(accuracy_values))\n",
        "print(\"Model no hidden layer: {0}\".format(accuracy_values_without_h))\n",
        "print(\"Model with 1 hidden layer:{0}\".format(accuracy_values_1_h))\n",
        "print(\"Model with 2 hidden layer:{0}\".format(accuracy_values_2_h))\n",
        "print(\"Model with 3 hidden layer:{0}\".format(accuracy_values_3_h))\n",
        "print(\"Model with 4 hidden layer:{0}\".format(accuracy_values_4_h))\n",
        "\n",
        "# Plot the data\n",
        "plt.plot(epoch_number, accuracy_values, label='CNN')\n",
        "plt.plot(epoch_number, accuracy_values_without_h, label='0_H_L')\n",
        "plt.plot(epoch_number, accuracy_values_1_h, label='1_H_L')\n",
        "plt.plot(epoch_number, accuracy_values_2_h, label='2_H_L')\n",
        "plt.plot(epoch_number, accuracy_values_3_h, label='3_H_L')\n",
        "plt.plot(epoch_number, accuracy_values_4_h, label='4_H_L')\n",
        "\n",
        "# Add a legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "## Anything better than 10% accuracy (randomly picking a class out of 10 classes)\n",
        "# means the network has learned something."
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Base model: [46.44, 54.48, 59.83, 60.15, 62.43, 62.83, 63.06, 63.14, 63.24, 62.89]\n",
            "Model no hidden layer: [7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2, 7.2]\n",
            "Model with 1 hidden layer:[10.29, 10.29, 10.29, 10.29, 10.29, 10.29, 10.29, 10.29, 10.29, 10.29]\n",
            "Model with 2 hidden layer:[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0]\n",
            "Model with 3 hidden layer:[11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5, 11.5]\n",
            "Model with 4 hidden layer:[11.31, 11.31, 11.31, 11.31, 11.31, 11.31, 11.31, 11.31, 11.31, 11.31]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAdS0lEQVR4nO3deXhV9b3v8fc3AwmjDDJJwCCohIhMAUWtRamHaqmWaik96AHFUnuw1drTgvqH95xrK9S2yqntveWpFqoUqlQu1gGqIE/P4SgIgkIZRCVIKPOMkmnne//YK5BAQjZh76ws83k9T569ht9e6+sWPvnxW2v9trk7IiISPWlhFyAiIvWjABcRiSgFuIhIRCnARUQiSgEuIhJRGQ15svPPP99zc3Mb8pQiIpG3evXqfe7e8dTtDRrgubm5rFq1qiFPKSISeWa2rabtGkIREYkoBbiISEQpwEVEIkoBLiISUQpwEZGIUoCLiESUAlxEJKIa9D5wEWnc3J0Khwp3KtzxE8sQq/Az7q+o8JPL7lRUODF3Kiri67ET+51YxSltgvef2ibm8XPGgn3u8W2VtcQqnJhTZdmDOk7Wm5WZTlZGGtmZ6TTPTCc7M53szDSaZ6aTdWJb9f1ZGWmkpVnY/zvqpAAXOUfuTkl5BcVlMUpjFZTFnLLyCkpjFZSWV1BWuS0W31a5ryxWQVm5n1wO2pVUvid4La18b/nJdqXBOSrXS6qcp2oIVvjJUK7c7lUC+NT9clL10E8Lgv/0sK+67/S26WRnpNG8WTqDerSjZVZyI1cBLp97lQH7WWmMz0rLKS6LBcsxjpfFOF5tubyW7fH3Hi+rONGm8jjHy2Ik+3tRMtONZulpZGakkZmeFl9ONzLTg/WM+LaszDRaZWdUa5ORnkaaQZoZZnZiOc3AzEhPs1r3p6VZtbZpVrUtwXvr3m/BtqrnSk+zE8dPNyMtrWqbeLuTy/Ht6WlUW08Ljhd/f+3HqjwvQFnMOV4Wo6Qs/v+quCz+yza+fHK98ud45Xp5jOLSYH95/M9AcfCL+sCnpSfee7zKe8titf9BeOOBL9K7U6uk/jlRgEskFZfFeG/7Id4pPMCmXUfjQVoa47MqIXwuAdssI40WzeI9qubN0k8sn9c8k65tsmneLNge7G/eLJ3sjPQTwZqZUSVsg8DNrBLClevx1yCs00+2MWv8/3yPimYZRrOMNGiemfJzxSq81l8OOe2aJ/18CnCJhMPHy1i97QArtx7kncIDrCs6TGmsAoAe7VvQpnlGnQF7cjmj+vZqQZ1BdkYaGem6vi9nLz3NaJmVkfShktoowKVR2n2kmJVbD/BO4QFWbj3A5t1HcYeMNKNfznnceXUuBbntKbiwHe1aNgu7XJFQKMAldO7Ox/s+5Z2tB1hZGA/t7QeOA9AiuPhz42VdGdKzHQO7t6N5s/SQKxZpHBTg0uDKYxVs3Hk0HtZbD7Bq2wH2HSsFoH3LZgzJbcf4YbkM7dmevl3baDhDpBYKcEm54rIYaz6JX3B8p/AA7247yKelMQBy2jXn2os7MqRne4bktqdXx5a6gCeSIAW4JN3hz8pYte3AiR72uh2HKYs5ZnBp59Z8fVBOENjt6Hpe8q/MizQVCQW4mbUFfgdcBjhwF7AZ+BOQCxQCY9z9YEqqlEZt5+HjJy44vrP1IJt3HwXi9zJfntOWu67pydDc9hRc2J7zWqT+Vi6RpiLRHvgMYJG732ZmzYAWwEPAEnefZmZTganAlBTVKUkUq3BKyuP3qJ72WnbyYYWSKq8lVdYrtx36rIx3PzlI0cH4BceWzdIZdGE7Rl3elSE92zOge1uyM3XBUSRV6gxwMzsPuBaYAODupUCpmd0CDA+azQaWoQBPuc9Ky/nzuzvYe6SY4iBYawri4vIYJVVeS6qsn+lpsURUPircslkG/bqdx51Xx3vYeV1b64KjSANKpAfeE9gL/N7M+gOrgfuAzu6+M2izC+hc05vNbBIwCaBHjx7nXHBTFatwXny3iJ//dTO7j5QAJ4O0cs6Gqq+tsjLo0DKt2kQ+p75mZ8T3Z2emkZVR+2tWlfVm6Wm6yCjSSCQS4BnAIOB77r7CzGYQHy45wd3dzGrs1rn7TGAmQEFBgWbLqYflH+7jJ69sZMPOI/Tv3pan/nkQBRe2U5CKNHGJBHgRUOTuK4L1+cQDfLeZdXX3nWbWFdiTqiKbqg/3HOWnr25i6aY9dGvbnBljB/DVyy+IxDSXIpJ6dQa4u+8ys+1mdqm7bwZGABuCn/HAtOB1YUorbUL2HSvhyTc+YO7K7bTITGfqjX2YcFWuLgiKSDWJ3oXyPWBOcAfKx8CdxL/N53kzmwhsA8akpsSmo7gsxjPLt/KbNz/ieFmMcVf04L4RF9OhVVbYpYlII5RQgLv7WqCghl0jkltO01RR4bz03j94fPFmdhw6zpfyOjH1xrykzx0sIp8vehIzZCu3HuAnr2zgvaLD5F/Qhse/cTlX9To/7LJEJAIU4CHZuu9Tpr22kcV/302XNtn84hv9GT2wmy5QikjCFOAN7OCnpfzn0i08+9Y2mmWk8cMbLuHuL1ykKVJF5KwpwBtISXmMP/zPNn61dAvHSsr55pAe/OCGi+nUOjvs0kQkohTgKebuvLpuF9MXbeKTA5/xxUs68tBNeVzapXXYpYlIxCnAU+jdTw7yk1c2snrbQfp0ac0f7hrKtZd0DLssEfmcUICnwPYDnzF90SZefn8nHVtnMe3r/fhGQXfSdYFSRJJIAZ5Eh4+X8es3P2TW8kLS0uD7Iy7mO9de1GDfUC0iTYuSJQnKYhXMeXsbM5Zs4dDxMm4dlMO//dOldDlPFyhFJHUU4OfA3Xl9w26mvbaJj/d9ylW9OvDwV/LIv+C8sEsTkSZAAV5P64oO8+grG1ix9QC9OrbkmQkFXHdpJ03xKiINRgF+lv5x6DiPL97MgjU76NCyGf/7a5cxdkh3MvVNNCLSwBTgCYpVOE8t/ZDfLPsQB747vBffHd6LNtn6kl4RCYcCPAGflpRz37y1vLFxN6Mu78rUG/uQ065F2GWJSBOnAK/DjkPHuXv2KjbvOsK/35zP+Ktywy5JRARQgJ/Rmk8O8u0/rKakLMasO/UUpYg0LgrwWixcu4MfzX+fLm2ymTfpCnp30twlItK4KMBPUVHhPLlkC/+5ZAtDe7bn/94+mPYtm4VdlojIaRTgVRwvjfFv89/jlfd38o3BOfxkdD+aZej2QBFpnBTggd1Hipn0h1W8v+MwD93Uh29/4SI9lCMijZoCHFi/4zB3z17FkeIyZt5RwA19O4ddkohInZp8gC9av5Mf/Ok92rXIZP49V9H3gjZhlyQikpAmG+Duzm+WfcTjizczsEdbfnvHYH29mYhESpMM8JLyGA/+eR0vrtnBLQMuYPqtl5OdqS8VFpFoaXIBvu9YCd95djWrtx3khzdcwr3X99bFShGJpCYV4Jt3HWXi7HfYd6yE34wbxE39uoZdkohIvSUU4GZWCBwFYkC5uxeYWXvgT0AuUAiMcfeDqSnz3L25aQ/fm7uGllnpPP+dYVye0zbskkREzsnZPKVynbsPcPeCYH0qsMTdLwaWBOuNjrvzu//6mImz3yH3/BYsnHyNwltEPhfOZQjlFmB4sDwbWAZMOcd6kqq0vIJHXlrP3JXb+XJ+F375zf60aNakRo1E5HMs0TRz4K9m5sBv3X0m0Nnddwb7dwE1Pv1iZpOASQA9evQ4x3ITd+izUu55bjVvf3yAe6/rzQM3XEJami5WisjnR6IBfo277zCzTsDrZrap6k539yDcTxOE/UyAgoKCGtsk20d7jzFx1jv841AxT3yzP6MH5jTEaUVEGlRCAe7uO4LXPWa2ABgK7Dazru6+08y6AntSWGfC/nvLPr47ZzVZGWnMnXQlgy9sF3ZJIiIpUWeAm1lLIM3djwbL/wT8B/ASMB6YFrwuTGWhiXj27W38r5f+Tu+OrXh6QoG+9kwkQsrKyigqKqK4uDjsUkKTnZ1NTk4OmZmJfdduIj3wzsCC4GGXDOCP7r7IzN4BnjezicA2YEw9az5n5bEKHn1lI7P+p5ARfTox41sDaZWli5UiUVJUVETr1q3Jzc1tkg/XuTv79++nqKiInj17JvSeOlPO3T8G+tewfT8w4qyrTLIjxWXc+8c1/O2DvXz7Cz2ZemMe6bpYKRI5xcXFTTa8AcyMDh06sHfv3oTfE+lu6rb9nzJx9ioK933K9Fv78c0hDXeXi4gkX1MN70pn+98f2QBf8fF+7nluNQ48O/EKhvXqEHZJIiINKpLfF/b8qu3c/vQK2rdsxv/716sV3iKSNLt27WLs2LH06tWLwYMHc9NNN/HBBx9gZvzqV7860e7ee+9l1qxZAEyYMIFu3bpRUlICwL59+8jNzU15rZEK8FiF89irG/nx/Pe58qIOvPivV5N7fsuwyxKRzwl3Z/To0QwfPpyPPvqI1atX89hjj7F79246derEjBkzKC0trfG96enpPPPMMw1ab2QC/NOScr7z7Gp++7ePuePKC/n9hCGc1zyxW21ERBLx5ptvkpmZyT333HNiW//+/enevTsdO3ZkxIgRzJ49u8b33n///TzxxBOUl5c3VLnRGAPfceg4E2e9w5Y9x/iPW/L5l2G5YZckIin073/5Oxv+cSSpx+x7QRse+Wr+GdusX7+ewYMH17p/ypQp3Hjjjdx1112n7evRowfXXHMNzz77LF/96lfPud5ENPoeuLvz/blr2HHoOL+fMEThLSKhueiii7jiiiv44x//WOP+Bx98kMcff5yKiooGqafR98DNjOm39gOgd6fWIVcjIg2hrp5yquTn5zN//vwztnnooYe47bbb+OIXv3javosvvpgBAwbw/PPPp6rEahp9Dxziwa3wFpFUu/766ykpKWHmzJkntr3//vts3779xHqfPn3o27cvf/nLX2o8xsMPP8zPf/7zlNcKEQlwEZGGYGYsWLCAN954g169epGfn8+DDz5Ily5dqrV7+OGHKSoqqvEY+fn5DBo0qCHKxdwbZIZXID6d7KpVqxrsfCISHRs3biQvLy/sMkJX0+dgZqurfBvaCeqBi4hElAJcRCSiFOAiIhGlABcRiSgFuIhIRCnARUQiSgEuIhJRCnARkSoWLVrEpZdeSu/evZk2bVqt7YYPH07V51oKCwu57LLLam2/bNkyRo0aldRaFeAiIoFYLMbkyZN57bXX2LBhA3PnzmXDhg1hl1WrRj+ZlYg0Qa9NhV3rknvMLv3gxtp71AArV66kd+/eXHTRRQCMHTuWhQsX0rdv3+TWkiQKcBGRwI4dO+jevfuJ9ZycHFasWFFr+3HjxtG8eXMASktLSUtr2EENBbiIND519JQbizlz5lBQEJ+ipLCwMOlj3HXRGLiISKBbt27Vpo4tKiqiW7duIVZ0ZgpwEZHAkCFD2LJlC1u3bqW0tJR58+Zx8803h11WrRTgIiKBjIwMnnrqKUaOHEleXh5jxowhPz953w60ZMkScnJyTvy89dZb53S8hOcDN7N0YBWww91HmVlPYB7QAVgN3OHupWc6huYDF5HaaD7wuFTNB34fsLHK+nTgCXfvDRwEJtajVhERqaeEAtzMcoCvAL8L1g24Hqj89s/ZwNdSUaCISJhGjx7NgAEDqv0sXry41vaLFy8+rf3o0aNTUluitxE+CfwYqPxm4Q7AIXcvD9aLgBov1ZrZJGASQI8ePepfqYhICBYsWHBW7UeOHMnIkSNTVE11dfbAzWwUsMfdV9fnBO4+090L3L2gY8eO9TmEiIjUIJEe+NXAzWZ2E5ANtAFmAG3NLCPohecAO1JXpoiInKrOHri7P+juOe6eC4wFlrr7OOBN4Lag2XhgYcqqFBGR05zLfeBTgAfM7EPiY+JPJ6ckERFJxFkFuLsvc/dRwfLH7j7U3Xu7+zfcvSQ1JYqINIy77rqLTp06nXFeb4AJEyYwf/78attatWpVa/u65gqvLz2JKSISmDBhAosWLQq7jIRpNkIRaXSmr5zOpgObknrMPu37MGXolDO2ufbaayksLEzqeVNJAS4iUg8/+tGPePTRR0OtQQEuIo1OXT3lxuDxxx/ntttuO7F+pjHwVNEYuIhIRCnARUQiSgEuIhL41re+xbBhw9i8eTM5OTk8/XTyHm+pPGblzwsvvHDOx9QYuIhIYO7cuQm1mzVr1mnbjh07Vmv73NxcysrK6ltWrdQDFxGJKPXARURqMXnyZJYvX15t23333cedd95ZY/t169Zxxx13VNuWlZXFihUrUlKfAlxEpBa//vWvz6p9v379WLt2bYqqOZ2GUEREIkoBLiISUQpwEZGIUoCLiESUAlxEJLB9+3auu+46+vbtS35+PjNmzKi1bWOYE1x3oYiIBDIyMvjFL37BoEGDOHr0KIMHD+aGG26gb9++YZdWIwW4iDQ6u376U0o2Jnc+8Ky8PnR56KEztunatStdu3YFoHXr1uTl5bFjxw4FuIhIlBQWFrJmzRquuOKKWtuEPSe4AlxEGp26esqpduzYMW699VaefPJJ2rRpU2u7sOcE10VMEZEqysrKuPXWWxk3bhxf//rXwy7njBTgIiIBd2fixInk5eXxwAMPhF1OnRTgIiKB5cuX8+yzz7J06VIGDBjAgAEDePXVV5N2/GTPCa4xcBGRwDXXXIO7J9S2McwJrh64iEhEqQcuInIGjXlO8DoD3Myygb8BWUH7+e7+iJn1BOYBHYDVwB3uXpr0CkVEQtSY5wRPZAilBLje3fsDA4Avm9mVwHTgCXfvDRwEJqauTBEROVWdAe5xlSPzmcGPA9cDlTO5zAa+lpIKRUSkRgldxDSzdDNbC+wBXgc+Ag65e3nQpAjoVst7J5nZKjNbtXfv3mTULCIiJBjg7h5z9wFADjAU6JPoCdx9prsXuHtBx44d61mmiIic6qxuI3T3Q8CbwDCgrZlVXgTNAXYkuTYRkQZVXFzM0KFD6d+/P/n5+TzyyCO1th0+fDirVq06sV7XfN/Lli1j1KhRSa23zgA3s45m1jZYbg7cAGwkHuSVs7iMBxYmtTIRkQaWlZXF0qVLee+991i7di2LFi3i7bffDrusWiVyH3hXYLaZpRMP/Ofd/WUz2wDMM7NHgTXA0ymsU0SakP96/gP2ba/9qcb6OL97K74w5pIztjGzEzMKlpWVUVZWhpkltY5kqjPA3f19YGAN2z8mPh4uIvK5EYvFGDx4MB9++CGTJ08+43zg48aNo3nz5gCUlpaSltawD7frSUwRaXTq6imnUnp6OmvXruXQoUOMHj2a9evX1zq2PWfOHAoKCoD4GHiyx7jrorlQRERq0LZtW6677joWLVoUdim1UoCLiAT27t3LoUOHADh+/Divv/46ffokfNd0g9MQiohIYOfOnYwfP55YLEZFRQVjxoxJ6rDIkiVLyMnJObH+wgsvMGzYsHofzxKd+zYZCgoKvOp9kyIilTZu3EheXl7YZYSups/BzFa7e8GpbTWEIiISURpCERE5g9GjR7N169Zq26ZPn87IkSNrbL948WKmTJlSbVvPnj1ZsGBB0mtTgIuInMHZBu/IkSNrDfdk0xCKiEhEKcBFRCJKAS4iElEKcBGRiFKAi4icIhaLMXDgwDM+xNMY5gPXXSgi0ui8OWsme7Z9nNRjdrrwIq6bMCmhtjNmzCAvL48jR44ktYZkUw9cRKSKoqIiXnnlFe6+++6wS6mTeuAi0ugk2lNOhfvvv5+f/exnHD16tM62Yc8Hrh64iEjg5ZdfplOnTgwePDih9nPmzGHt2rWsXbuWV199NcXVnU4BLiISWL58OS+99BK5ubmMHTuWpUuXcvvtt4ddVq0U4CIigccee4yioiIKCwuZN28e119/Pc8991zYZdVKAS4i0kAq5wOv/HnrrbfO6XiaD1xEGgXNBx6n+cBFRJoA3UYoInIGmg9cRCQB7o6ZhV1GNQ05H/jZDmlrCEVEGoXs7Gz2799/1iH2eeHu7N+/n+zs7ITfox64iDQKOTk5FBUVsXfv3rBLCU12dna1b62viwJcRBqFzMxMevbsGXYZkVLnEIqZdTezN81sg5n93czuC7a3N7PXzWxL8Nou9eWKiEilRMbAy4Efuntf4Epgspn1BaYCS9z9YmBJsC4iIg2kzgB3953u/m6wfBTYCHQDbgFmB81mA19LVZEiInK6s7oLxcxygYHACqCzu+8Mdu0COtfynklmtsrMVjXlixMiIsmWcICbWSvgz8D97l7tayo8ft9Pjff+uPtMdy9w94KOHTueU7EiInJSQgFuZpnEw3uOu78YbN5tZl2D/V2BPakpUUREapLIXSgGPA1sdPdfVtn1EjA+WB4PLEx+eSIiUptE7gO/GrgDWGdma4NtDwHTgOfNbCKwDRiTmhJFRKQmdQa4u/83UNvkBCOSW46IiCRKc6GIiESUAlxEJKIU4CIiEaUAFxGJKAW4iEhEKcBFRCJKAS4iElEKcBGRiFKAi4hElAJcRCSiFOAiIhGlABcRiSgFuIhIRCnARUQiSgEuIhJRCnARkYhSgIuIRJQCXEQkohTgIiIRpQAXEYkoBbiISEQpwEVEIkoBLiISURlhF5CI5x6ezuHd28MuQ0SkXs7r3J3bfzIl6cdVD1xEJKIi0QNPxW8uEZGoq7MHbmbPmNkeM1tfZVt7M3vdzLYEr+1SW6aIiJwqkR74LOAp4A9Vtk0Flrj7NDObGqynrJs8feV0Nh3YlKrDi4ikVJ/2fZgyNPkRWWeAu/vfzCz3lM23AMOD5dnAMlIY4PnPrWDAR0WpOryISEqV9ToMQ5N/3PqOgXd2953B8i6gc20NzWwSMAmgR48e9TpZQZcCSg62qtd7RUTCltWlT0qOe84XMd3dzczPsH8mMBOgoKCg1nZn0uWhh+pZnYjI51d9byPcbWZdAYLXPckrSUREElHfAH8JGB8sjwcWJqccERFJVCK3Ec4F3gIuNbMiM5sITANuMLMtwJeCdRERaUCJ3IXyrVp2jUhyLSIichb0KL2ISEQpwEVEIkoBLiISUZGYzIrXpsKudWFXISJSP136wY3Jv9dDPXARkYiKRg88Bb+5RESiTj1wEZGIUoCLiESUAlxEJKIU4CIiEaUAFxGJKAW4iEhEKcBFRCJKAS4iElHmXq9vOavfycz2Atsa7ISpcT6wL+wiGgl9FtXp86hOn8dJ5/pZXOjuHU/d2KAB/nlgZqvcvSDsOhoDfRbV6fOoTp/HSan6LDSEIiISUQpwEZGIUoCfvZlhF9CI6LOoTp9Hdfo8TkrJZ6ExcBGRiFIPXEQkohTgIiIRpQBPgJl1N7M3zWyDmf3dzO4Lu6bGwMzSzWyNmb0cdi1hM7O2ZjbfzDaZ2UYzGxZ2TWExsx8Ef0/Wm9lcM8sOu6aGZGbPmNkeM1tfZVt7M3vdzLYEr+2ScS4FeGLKgR+6e1/gSmCymfUNuabG4D5gY9hFNBIzgEXu3gfoTxP9XMysG/B9oMDdLwPSgbHhVtXgZgFfPmXbVGCJu18MLAnWz5kCPAHuvtPd3w2WjxL/y9kt3KrCZWY5wFeA34VdS9jM7DzgWuBpAHcvdfdD4VYVqgyguZllAC2Af4RcT4Ny978BB07ZfAswO1ieDXwtGedSgJ8lM8sFBgIrwq0kdE8CPwYqwi6kEegJ7AV+Hwwp/c7MWoZdVBjcfQfwc+ATYCdw2N3/Gm5VjUJnd98ZLO8COifjoArws2BmrYA/A/e7+5Gw6wmLmY0C9rj76rBraSQygEHA/3H3gcCnJOmfyFETjO3eQvyX2gVASzO7PdyqGheP37udlPu3FeAJMrNM4uE9x91fDLuekF0N3GxmhcA84Hozey7ckkJVBBS5e+W/yuYTD/Sm6EvAVnff6+5lwIvAVSHX1BjsNrOuAMHrnmQcVAGeADMz4uObG939l2HXEzZ3f9Ddc9w9l/gFqqXu3mR7We6+C9huZpcGm0YAG0IsKUyfAFeaWYvg780ImugF3VO8BIwPlscDC5NxUAV4Yq4G7iDe01wb/NwUdlHSqHwPmGNm7wMDgJ+GXE8ogn+FzAfeBdYRz5gm9Ui9mc0F3gIuNbMiM5sITANuMLMtxP+VMi0p59Kj9CIi0aQeuIhIRCnARUQiSgEuIhJRCnARkYhSgIuIRJQCXEQkohTgIiIR9f8BYD9+8bXdMuoAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "55NFQxxNip8Y"
      },
      "source": [
        "## Question 2\n",
        "CNN with sigmoid activation function\n",
        "\n",
        "Should I change all relu functions to sigmoid including fully connect layer?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P0mSTxWli3xp",
        "outputId": "679cfd3a-d706-4cbc-e1ae-d6d96491bacb"
      },
      "source": [
        "class Net_sigmoid(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_sigmoid, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
        "        self.fc1 = nn.Linear(16*5*5, 120)\n",
        "        self.fc2 = nn.Linear(120, 120)\n",
        "        self.fc3 = nn.Linear(120, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(torch.sigmoid(self.conv1(x)))\n",
        "        x = self.pool(torch.sigmoid(self.conv2(x)))\n",
        "        x = x.view(-1, 16*5*5)\n",
        "        x = torch.sigmoid(self.fc1(x))\n",
        "        x = torch.sigmoid(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "        \n",
        "print(Net_sigmoid())"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net_sigmoid(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=120, bias=True)\n",
            "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lg4HmM09Xf5z"
      },
      "source": [
        "net_sigmoid = Net_sigmoid()\n",
        "if CUDA:\n",
        "    net_sigmoid = net_sigmoid.cuda()"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5cuno_x1HA_a",
        "outputId": "7b509940-6f7c-4d7e-d383-6377681333d5"
      },
      "source": [
        "# Training with sigmoid\n",
        "# criterion is Cross Entropy loss\n",
        "# optimizer is SGD\n",
        "accuracy_sigmoid = []\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader):\n",
        "        if CUDA:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        else:\n",
        "            inputs = inputs.cpu()\n",
        "            labels = labels.cpu()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net_sigmoid(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:\n",
        "            print('[epoch%d, itr%5d] %.3f' %\n",
        "                  (epoch+1, i+1, running_loss/2000))\n",
        "            running_loss = 0.0\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            if CUDA:\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "            else:\n",
        "                images = images.cpu()\n",
        "                labels = labels.cpu()\n",
        "\n",
        "            outputs = net_sigmoid(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            if not CUDA:\n",
        "                correct += (predicted.cpu() == labels.cpu()).sum().item()\n",
        "            else:\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        TextAccuracy = 100 * correct / total\n",
        "        accuracy_sigmoid += [TextAccuracy]\n",
        "        print('Epoch=%d Test Accuracy=%.3f' %\n",
        "              (epoch+1, TextAccuracy))\n",
        "      \n",
        "print('Finished Training with sigmoid')\n",
        "\n"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch1, itr 2000] 2.332\n",
            "[epoch1, itr 4000] 2.324\n",
            "[epoch1, itr 6000] 2.329\n",
            "[epoch1, itr 8000] 2.330\n",
            "[epoch1, itr10000] 2.325\n",
            "[epoch1, itr12000] 2.328\n",
            "Epoch=1 Test Accuracy=10.000\n",
            "[epoch2, itr 2000] 2.330\n",
            "[epoch2, itr 4000] 2.325\n",
            "[epoch2, itr 6000] 2.326\n",
            "[epoch2, itr 8000] 2.327\n",
            "[epoch2, itr10000] 2.328\n",
            "[epoch2, itr12000] 2.331\n",
            "Epoch=2 Test Accuracy=10.000\n",
            "[epoch3, itr 2000] 2.325\n",
            "[epoch3, itr 4000] 2.327\n",
            "[epoch3, itr 6000] 2.330\n",
            "[epoch3, itr 8000] 2.327\n",
            "[epoch3, itr10000] 2.326\n",
            "[epoch3, itr12000] 2.331\n",
            "Epoch=3 Test Accuracy=10.000\n",
            "[epoch4, itr 2000] 2.330\n",
            "[epoch4, itr 4000] 2.325\n",
            "[epoch4, itr 6000] 2.329\n",
            "[epoch4, itr 8000] 2.326\n",
            "[epoch4, itr10000] 2.327\n",
            "[epoch4, itr12000] 2.327\n",
            "Epoch=4 Test Accuracy=10.000\n",
            "[epoch5, itr 2000] 2.331\n",
            "[epoch5, itr 4000] 2.327\n",
            "[epoch5, itr 6000] 2.329\n",
            "[epoch5, itr 8000] 2.328\n",
            "[epoch5, itr10000] 2.326\n",
            "[epoch5, itr12000] 2.326\n",
            "Epoch=5 Test Accuracy=10.000\n",
            "[epoch6, itr 2000] 2.331\n",
            "[epoch6, itr 4000] 2.326\n",
            "[epoch6, itr 6000] 2.329\n",
            "[epoch6, itr 8000] 2.326\n",
            "[epoch6, itr10000] 2.326\n",
            "[epoch6, itr12000] 2.330\n",
            "Epoch=6 Test Accuracy=10.000\n",
            "[epoch7, itr 2000] 2.324\n",
            "[epoch7, itr 4000] 2.332\n",
            "[epoch7, itr 6000] 2.327\n",
            "[epoch7, itr 8000] 2.326\n",
            "[epoch7, itr10000] 2.328\n",
            "[epoch7, itr12000] 2.329\n",
            "Epoch=7 Test Accuracy=10.000\n",
            "[epoch8, itr 2000] 2.327\n",
            "[epoch8, itr 4000] 2.325\n",
            "[epoch8, itr 6000] 2.324\n",
            "[epoch8, itr 8000] 2.329\n",
            "[epoch8, itr10000] 2.328\n",
            "[epoch8, itr12000] 2.334\n",
            "Epoch=8 Test Accuracy=10.000\n",
            "[epoch9, itr 2000] 2.327\n",
            "[epoch9, itr 4000] 2.328\n",
            "[epoch9, itr 6000] 2.329\n",
            "[epoch9, itr 8000] 2.329\n",
            "[epoch9, itr10000] 2.328\n",
            "[epoch9, itr12000] 2.325\n",
            "Epoch=9 Test Accuracy=10.000\n",
            "[epoch10, itr 2000] 2.328\n",
            "[epoch10, itr 4000] 2.326\n",
            "[epoch10, itr 6000] 2.332\n",
            "[epoch10, itr 8000] 2.324\n",
            "[epoch10, itr10000] 2.324\n",
            "[epoch10, itr12000] 2.330\n",
            "Epoch=10 Test Accuracy=10.000\n",
            "Finished Training with sigmoid\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "U-AJgq5jHb42",
        "outputId": "b124f0c9-4a85-4c65-af95-741b145b308f"
      },
      "source": [
        "print(accuracy_sigmoid)\n",
        "\n",
        "plt.plot(epoch_number, accuracy_values, label='CNN_with_Relu')\n",
        "plt.plot(epoch_number, accuracy_sigmoid, label='CNN_with_Sigmoid')\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y_IJS0XrI-Zn"
      },
      "source": [
        "## Question 3\n",
        "\n",
        "With 5*5 filter, SAME convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LB8cJsXzI9x3",
        "outputId": "6b90f11f-000d-43b4-acf7-830d20ab55e7"
      },
      "source": [
        "class Net_5_SAME(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_5_SAME, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 5, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 5, padding=1)\n",
        "        self.fc1 = nn.Linear(16*6*6, 120)\n",
        "        self.fc2 = nn.Linear(120, 120)\n",
        "        self.fc3 = nn.Linear(120, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # print(x.size())\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        # print(x.size())\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        # print(x.size())\n",
        "        x = x.view(-1, 16*6*6)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "print(Net_5_SAME())"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net_5_SAME(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=120, bias=True)\n",
            "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bznMlk3VQzhM"
      },
      "source": [
        "net_5_same = Net_5_SAME()\n",
        "if CUDA:\n",
        "    net_5_same = net_5_same.cuda()"
      ],
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vgazhFAQXrk",
        "outputId": "9ffe08a9-eae6-419e-963f-9eb1cad8c4c9"
      },
      "source": [
        "accuracy_5_same = []\n",
        "\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "        if CUDA:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        else:\n",
        "            inputs = inputs.cpu()\n",
        "            labels = labels.cpu()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net_5_same(inputs)\n",
        "        # if i == 1:\n",
        "        #   print(outputs.size())\n",
        "        #   print(labels.size())\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:\n",
        "          print('[epoch%d itr%5d] loss: %.3f' % (epoch+1, i+1, running_loss/2000))\n",
        "          running_loss = 0.0\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            if CUDA:\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "            else:\n",
        "                images = images.cpu()\n",
        "                labels = labels.cpu()\n",
        "\n",
        "            outputs = net_5_same(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            if not CUDA:\n",
        "                correct += (predicted.cpu() == labels.cpu()).sum().item()\n",
        "            else:\n",
        "                correct += (predicted == labels).sum().item()\n",
        "          \n",
        "        TestAccuracy = 100 * correct / total\n",
        "        accuracy_5_same += [TestAccuracy]\n",
        "        print(\"Epoch=%d Test Accuracy=%.3f\" %\n",
        "              (epoch+1, TestAccuracy))\n",
        "        \n",
        "print(\"Finished Training with 5*5 filter in SAME convolution\")        "
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch1 itr 2000] loss: 2.304\n",
            "[epoch1 itr 4000] loss: 2.304\n",
            "[epoch1 itr 6000] loss: 2.304\n",
            "[epoch1 itr 8000] loss: 2.303\n",
            "[epoch1 itr10000] loss: 2.305\n",
            "[epoch1 itr12000] loss: 2.305\n",
            "Epoch=1 Test Accuracy=10.000\n",
            "[epoch2 itr 2000] loss: 2.302\n",
            "[epoch2 itr 4000] loss: 2.305\n",
            "[epoch2 itr 6000] loss: 2.305\n",
            "[epoch2 itr 8000] loss: 2.304\n",
            "[epoch2 itr10000] loss: 2.305\n",
            "[epoch2 itr12000] loss: 2.304\n",
            "Epoch=2 Test Accuracy=10.000\n",
            "[epoch3 itr 2000] loss: 2.304\n",
            "[epoch3 itr 4000] loss: 2.305\n",
            "[epoch3 itr 6000] loss: 2.305\n",
            "[epoch3 itr 8000] loss: 2.303\n",
            "[epoch3 itr10000] loss: 2.304\n",
            "[epoch3 itr12000] loss: 2.304\n",
            "Epoch=3 Test Accuracy=10.000\n",
            "[epoch4 itr 2000] loss: 2.304\n",
            "[epoch4 itr 4000] loss: 2.304\n",
            "[epoch4 itr 6000] loss: 2.303\n",
            "[epoch4 itr 8000] loss: 2.304\n",
            "[epoch4 itr10000] loss: 2.305\n",
            "[epoch4 itr12000] loss: 2.304\n",
            "Epoch=4 Test Accuracy=10.000\n",
            "[epoch5 itr 2000] loss: 2.304\n",
            "[epoch5 itr 4000] loss: 2.304\n",
            "[epoch5 itr 6000] loss: 2.304\n",
            "[epoch5 itr 8000] loss: 2.304\n",
            "[epoch5 itr10000] loss: 2.305\n",
            "[epoch5 itr12000] loss: 2.304\n",
            "Epoch=5 Test Accuracy=10.000\n",
            "[epoch6 itr 2000] loss: 2.304\n",
            "[epoch6 itr 4000] loss: 2.303\n",
            "[epoch6 itr 6000] loss: 2.304\n",
            "[epoch6 itr 8000] loss: 2.305\n",
            "[epoch6 itr10000] loss: 2.303\n",
            "[epoch6 itr12000] loss: 2.305\n",
            "Epoch=6 Test Accuracy=10.000\n",
            "[epoch7 itr 2000] loss: 2.305\n",
            "[epoch7 itr 4000] loss: 2.304\n",
            "[epoch7 itr 6000] loss: 2.302\n",
            "[epoch7 itr 8000] loss: 2.304\n",
            "[epoch7 itr10000] loss: 2.305\n",
            "[epoch7 itr12000] loss: 2.305\n",
            "Epoch=7 Test Accuracy=10.000\n",
            "[epoch8 itr 2000] loss: 2.304\n",
            "[epoch8 itr 4000] loss: 2.304\n",
            "[epoch8 itr 6000] loss: 2.304\n",
            "[epoch8 itr 8000] loss: 2.304\n",
            "[epoch8 itr10000] loss: 2.304\n",
            "[epoch8 itr12000] loss: 2.305\n",
            "Epoch=8 Test Accuracy=10.000\n",
            "[epoch9 itr 2000] loss: 2.304\n",
            "[epoch9 itr 4000] loss: 2.304\n",
            "[epoch9 itr 6000] loss: 2.304\n",
            "[epoch9 itr 8000] loss: 2.304\n",
            "[epoch9 itr10000] loss: 2.305\n",
            "[epoch9 itr12000] loss: 2.304\n",
            "Epoch=9 Test Accuracy=10.000\n",
            "[epoch10 itr 2000] loss: 2.305\n",
            "[epoch10 itr 4000] loss: 2.304\n",
            "[epoch10 itr 6000] loss: 2.303\n",
            "[epoch10 itr 8000] loss: 2.304\n",
            "[epoch10 itr10000] loss: 2.305\n",
            "[epoch10 itr12000] loss: 2.304\n",
            "Epoch=10 Test Accuracy=10.000\n",
            "Finished Training with 5*5 filter in SAME convolution\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2mqaBsY4Wy1D"
      },
      "source": [
        "Network with 3*3 filter, Valid convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tWzN_8CwWoV5",
        "outputId": "2df86f7f-69c3-49b9-f4f7-82c38b686933"
      },
      "source": [
        "class Net_3_VALID(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_3_VALID, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3)\n",
        "        self.fc1 = nn.Linear(16 * 6 * 6, 120)\n",
        "        self.fc2 = nn.Linear(120, 120)\n",
        "        self.fc3 = nn.Linear(120, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        # print(x.size())\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        # print(x.size())\n",
        "        x = x.view(-1, 16 * 6 * 6)\n",
        "        # print(x.size())\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "print(Net_3_VALID())"
      ],
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net_3_VALID(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1))\n",
            "  (fc1): Linear(in_features=576, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=120, bias=True)\n",
            "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tHiBAOHXXA9x"
      },
      "source": [
        "net_3_valid = Net_3_VALID()\n",
        "if CUDA:\n",
        "    net_3_valid = net_3_valid.cuda()"
      ],
      "execution_count": 131,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5NQblVbYXBSP",
        "outputId": "34c4ddd7-2a6f-41c3-ddbd-dadf4a9774ea"
      },
      "source": [
        "accuracy_3_valid = []\n",
        "\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "        if CUDA:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        else:\n",
        "            inputs = inputs.cpu()\n",
        "            labels = labels.cpu()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net_3_valid(inputs)\n",
        "        # if i == 1:\n",
        "        #     print(outputs.size())\n",
        "        #     print(labels.size())\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:\n",
        "          print('[epoch%d itr%5d] loss: %.3f' % (epoch+1, i+1, running_loss/2000))\n",
        "          running_loss = 0.0\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            if CUDA:\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "            else:\n",
        "                images = images.cpu()\n",
        "                labels = labels.cpu()\n",
        "\n",
        "            outputs = net_3_valid(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            if not CUDA:\n",
        "                correct += (predicted.cpu() == labels.cpu()).sum().item()\n",
        "            else:\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        TestAccuracy = 100 * correct / total\n",
        "        accuracy_3_valid += [TestAccuracy]\n",
        "        print(\"Epoch=%d Test Accuracy=%.3f\" %\n",
        "              (epoch+1, TestAccuracy))\n",
        "        \n",
        "print(\"Finished Training with 3*3 filter in VALID convolution\")        "
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch1 itr 2000] loss: 2.305\n",
            "[epoch1 itr 4000] loss: 2.304\n",
            "[epoch1 itr 6000] loss: 2.305\n",
            "[epoch1 itr 8000] loss: 2.306\n",
            "[epoch1 itr10000] loss: 2.304\n",
            "[epoch1 itr12000] loss: 2.305\n",
            "Epoch=1 Test Accuracy=10.000\n",
            "[epoch2 itr 2000] loss: 2.304\n",
            "[epoch2 itr 4000] loss: 2.304\n",
            "[epoch2 itr 6000] loss: 2.306\n",
            "[epoch2 itr 8000] loss: 2.304\n",
            "[epoch2 itr10000] loss: 2.304\n",
            "[epoch2 itr12000] loss: 2.305\n",
            "Epoch=2 Test Accuracy=10.000\n",
            "[epoch3 itr 2000] loss: 2.304\n",
            "[epoch3 itr 4000] loss: 2.305\n",
            "[epoch3 itr 6000] loss: 2.305\n",
            "[epoch3 itr 8000] loss: 2.305\n",
            "[epoch3 itr10000] loss: 2.305\n",
            "[epoch3 itr12000] loss: 2.304\n",
            "Epoch=3 Test Accuracy=10.000\n",
            "[epoch4 itr 2000] loss: 2.305\n",
            "[epoch4 itr 4000] loss: 2.305\n",
            "[epoch4 itr 6000] loss: 2.305\n",
            "[epoch4 itr 8000] loss: 2.305\n",
            "[epoch4 itr10000] loss: 2.304\n",
            "[epoch4 itr12000] loss: 2.304\n",
            "Epoch=4 Test Accuracy=10.000\n",
            "[epoch5 itr 2000] loss: 2.304\n",
            "[epoch5 itr 4000] loss: 2.305\n",
            "[epoch5 itr 6000] loss: 2.305\n",
            "[epoch5 itr 8000] loss: 2.305\n",
            "[epoch5 itr10000] loss: 2.305\n",
            "[epoch5 itr12000] loss: 2.305\n",
            "Epoch=5 Test Accuracy=10.000\n",
            "[epoch6 itr 2000] loss: 2.304\n",
            "[epoch6 itr 4000] loss: 2.305\n",
            "[epoch6 itr 6000] loss: 2.304\n",
            "[epoch6 itr 8000] loss: 2.306\n",
            "[epoch6 itr10000] loss: 2.305\n",
            "[epoch6 itr12000] loss: 2.304\n",
            "Epoch=6 Test Accuracy=10.000\n",
            "[epoch7 itr 2000] loss: 2.305\n",
            "[epoch7 itr 4000] loss: 2.304\n",
            "[epoch7 itr 6000] loss: 2.305\n",
            "[epoch7 itr 8000] loss: 2.305\n",
            "[epoch7 itr10000] loss: 2.305\n",
            "[epoch7 itr12000] loss: 2.304\n",
            "Epoch=7 Test Accuracy=10.000\n",
            "[epoch8 itr 2000] loss: 2.304\n",
            "[epoch8 itr 4000] loss: 2.304\n",
            "[epoch8 itr 6000] loss: 2.305\n",
            "[epoch8 itr 8000] loss: 2.305\n",
            "[epoch8 itr10000] loss: 2.304\n",
            "[epoch8 itr12000] loss: 2.305\n",
            "Epoch=8 Test Accuracy=10.000\n",
            "[epoch9 itr 2000] loss: 2.305\n",
            "[epoch9 itr 4000] loss: 2.304\n",
            "[epoch9 itr 6000] loss: 2.306\n",
            "[epoch9 itr 8000] loss: 2.305\n",
            "[epoch9 itr10000] loss: 2.304\n",
            "[epoch9 itr12000] loss: 2.305\n",
            "Epoch=9 Test Accuracy=10.000\n",
            "[epoch10 itr 2000] loss: 2.305\n",
            "[epoch10 itr 4000] loss: 2.305\n",
            "[epoch10 itr 6000] loss: 2.305\n",
            "[epoch10 itr 8000] loss: 2.305\n",
            "[epoch10 itr10000] loss: 2.304\n",
            "[epoch10 itr12000] loss: 2.305\n",
            "Epoch=10 Test Accuracy=10.000\n",
            "Finished Training with 5*5 filter in SAME convolution\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XiQ56cFAaHpg"
      },
      "source": [
        "Network with 3*3 filter, SAME convolution"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UL71uvIzaGla",
        "outputId": "f70d5e0f-e1e3-4179-aa6c-b22359533b48"
      },
      "source": [
        "class Net_3_SAME(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net_3_SAME, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 6, 3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(6, 16, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(16*8*8, 120)\n",
        "        self.fc2 = nn.Linear(120, 120)\n",
        "        self.fc3 = nn.Linear(120, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(F.relu(self.conv1(x)))\n",
        "        x = self.pool(F.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 16*8*8)\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = F.relu(self.fc2(x))\n",
        "        # x = F.softmax(self.fc3(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "print(Net_3_SAME())"
      ],
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net_3_SAME(\n",
            "  (conv1): Conv2d(3, 6, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (conv2): Conv2d(6, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (fc1): Linear(in_features=1024, out_features=120, bias=True)\n",
            "  (fc2): Linear(in_features=120, out_features=120, bias=True)\n",
            "  (fc3): Linear(in_features=120, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vez-ik5YaGln"
      },
      "source": [
        "net_3_same = Net_3_SAME()\n",
        "if CUDA:\n",
        "    net_3_same = net_3_same.cuda()"
      ],
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gs-bmPOzaGln",
        "outputId": "7ed651dd-5590-4a6c-9a5e-5b84611c5c8a"
      },
      "source": [
        "accuracy_3_same = []\n",
        "\n",
        "for epoch in range(10):\n",
        "    running_loss = 0.0\n",
        "    for i, (inputs, labels) in enumerate(trainloader, 0):\n",
        "        if CUDA:\n",
        "            inputs = inputs.cuda()\n",
        "            labels = labels.cuda()\n",
        "        else:\n",
        "            inputs = inputs.cpu()\n",
        "            labels = labels.cpu()\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        outputs = net_3_same(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        if i % 2000 == 1999:\n",
        "          print('[epoch%d itr%5d] loss: %.3f' % (epoch+1, i+1, running_loss/2000))\n",
        "          running_loss = 0.0\n",
        "    \n",
        "    correct = 0\n",
        "    total = 0\n",
        "    with torch.no_grad():\n",
        "        for images, labels in testloader:\n",
        "            if CUDA:\n",
        "                images = images.cuda()\n",
        "                labels = labels.cuda()\n",
        "            else:\n",
        "                images = images.cpu()\n",
        "                labels = labels.cpu()\n",
        "\n",
        "            outputs = net_3_same(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            if not CUDA:\n",
        "                correct += (predicted.cpu() == labels.cpu()).sum().item()\n",
        "            else:\n",
        "                correct += (predicted == labels).sum().item()\n",
        "\n",
        "        TestAccuracy = 100 * correct / total\n",
        "        accuracy_3_same += [TestAccuracy]\n",
        "        print(\"Epoch=%d Test Accuracy=%.3f\" %\n",
        "              (epoch+1, TestAccuracy))\n",
        "        \n",
        "print(\"Finished Training with 3*3 filter in SAME convolution\")        "
      ],
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[epoch1 itr 2000] loss: 2.304\n",
            "[epoch1 itr 4000] loss: 2.303\n",
            "[epoch1 itr 6000] loss: 2.303\n",
            "[epoch1 itr 8000] loss: 2.304\n",
            "[epoch1 itr10000] loss: 2.304\n",
            "[epoch1 itr12000] loss: 2.305\n",
            "Epoch=1 Test Accuracy=9.110\n",
            "[epoch2 itr 2000] loss: 2.303\n",
            "[epoch2 itr 4000] loss: 2.304\n",
            "[epoch2 itr 6000] loss: 2.304\n",
            "[epoch2 itr 8000] loss: 2.304\n",
            "[epoch2 itr10000] loss: 2.304\n",
            "[epoch2 itr12000] loss: 2.304\n",
            "Epoch=2 Test Accuracy=9.110\n",
            "[epoch3 itr 2000] loss: 2.304\n",
            "[epoch3 itr 4000] loss: 2.304\n",
            "[epoch3 itr 6000] loss: 2.304\n",
            "[epoch3 itr 8000] loss: 2.303\n",
            "[epoch3 itr10000] loss: 2.305\n",
            "[epoch3 itr12000] loss: 2.304\n",
            "Epoch=3 Test Accuracy=9.110\n",
            "[epoch4 itr 2000] loss: 2.303\n",
            "[epoch4 itr 4000] loss: 2.305\n",
            "[epoch4 itr 6000] loss: 2.304\n",
            "[epoch4 itr 8000] loss: 2.304\n",
            "[epoch4 itr10000] loss: 2.302\n",
            "[epoch4 itr12000] loss: 2.305\n",
            "Epoch=4 Test Accuracy=9.110\n",
            "[epoch5 itr 2000] loss: 2.304\n",
            "[epoch5 itr 4000] loss: 2.303\n",
            "[epoch5 itr 6000] loss: 2.304\n",
            "[epoch5 itr 8000] loss: 2.303\n",
            "[epoch5 itr10000] loss: 2.304\n",
            "[epoch5 itr12000] loss: 2.305\n",
            "Epoch=5 Test Accuracy=9.110\n",
            "[epoch6 itr 2000] loss: 2.304\n",
            "[epoch6 itr 4000] loss: 2.304\n",
            "[epoch6 itr 6000] loss: 2.304\n",
            "[epoch6 itr 8000] loss: 2.304\n",
            "[epoch6 itr10000] loss: 2.304\n",
            "[epoch6 itr12000] loss: 2.303\n",
            "Epoch=6 Test Accuracy=9.110\n",
            "[epoch7 itr 2000] loss: 2.304\n",
            "[epoch7 itr 4000] loss: 2.304\n",
            "[epoch7 itr 6000] loss: 2.306\n",
            "[epoch7 itr 8000] loss: 2.303\n",
            "[epoch7 itr10000] loss: 2.304\n",
            "[epoch7 itr12000] loss: 2.303\n",
            "Epoch=7 Test Accuracy=9.110\n",
            "[epoch8 itr 2000] loss: 2.305\n",
            "[epoch8 itr 4000] loss: 2.304\n",
            "[epoch8 itr 6000] loss: 2.304\n",
            "[epoch8 itr 8000] loss: 2.304\n",
            "[epoch8 itr10000] loss: 2.303\n",
            "[epoch8 itr12000] loss: 2.304\n",
            "Epoch=8 Test Accuracy=9.110\n",
            "[epoch9 itr 2000] loss: 2.304\n",
            "[epoch9 itr 4000] loss: 2.305\n",
            "[epoch9 itr 6000] loss: 2.304\n",
            "[epoch9 itr 8000] loss: 2.305\n",
            "[epoch9 itr10000] loss: 2.303\n",
            "[epoch9 itr12000] loss: 2.304\n",
            "Epoch=9 Test Accuracy=9.110\n",
            "[epoch10 itr 2000] loss: 2.304\n",
            "[epoch10 itr 4000] loss: 2.304\n",
            "[epoch10 itr 6000] loss: 2.304\n",
            "[epoch10 itr 8000] loss: 2.303\n",
            "[epoch10 itr10000] loss: 2.304\n",
            "[epoch10 itr12000] loss: 2.304\n",
            "Epoch=10 Test Accuracy=9.110\n",
            "Finished Training with 5*5 filter in SAME convolution\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 334
        },
        "id": "KKrFemaNaY-_",
        "outputId": "390874ea-f899-46a8-e70c-0d2fdebc9fed"
      },
      "source": [
        "# test plots\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "print(\"Model with 5*5 filter (VALID): {0}\".format(accuracy_values))\n",
        "print(\"Model with 5*5 filter (SAME):{0}\".format(accuracy_5_same))\n",
        "print(\"Model with 3*3 filter (VALID):{0}\".format(accuracy_3_valid))\n",
        "print(\"Model with 3*3 filter (SAME):{0}\".format(accuracy_3_same))\n",
        "\n",
        "# Plot the data\n",
        "plt.plot(epoch_number, accuracy_values, label='CNN_5_valid')\n",
        "plt.plot(epoch_number, accuracy_5_same, label='CNN_5_same')\n",
        "plt.plot(epoch_number, accuracy_3_valid, label='CNN_3_valid')\n",
        "\n",
        "plt.plot(epoch_number, accuracy_3_same, label='CNN_3_same')\n",
        "\n",
        "# Add a legend\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()\n",
        "\n",
        "## Anything better than 10% accuracy (randomly picking a class out of 10 classes)\n",
        "# means the network has learned something."
      ],
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model with 5*5 filter (VALID): [46.44, 54.48, 59.83, 60.15, 62.43, 62.83, 63.06, 63.14, 63.24, 62.89]\n",
            "Model with 5*5 filter (SAME):[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0]\n",
            "Model with 3*3 filter (VALID):[10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0, 10.0]\n",
            "Model with 3*3 filter (SAME):[9.11, 9.11, 9.11, 9.11, 9.11, 9.11, 9.11, 9.11, 9.11, 9.11]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3deXhU9d338fc3k5UdQoxsNoAgENlTg8KtCNWCoEDdsFURaLE+laq11w2KV7WVqrTcUq33XUsrglYFHiwFtPqoiLfWAppAIKwimwTZ9y3b5Pf8MZNAIMsEJpkc8nldV645c87vnPOdQT85c3LOd8w5h4iIeE9UpAsQEZHzowAXEfEoBbiIiEcpwEVEPEoBLiLiUdE1ubPmzZu7lJSUmtyliIjnZWZm7nfOJZ09v0YDPCUlhYyMjJrcpYiI55nZ9rLm6xSKiIhHKcBFRDxKAS4i4lEKcBERj1KAi4h4lAJcRMSjFOAiIh5Vo9eBi4g3OOcoclDkHEXO4Rz4i1zweWB54Hnpsf6iwNgi5/A7R1FwTPG6/qLA/MD6Z27TnTGG4HYCY8+cXxTcZsXbDswr3kZcjI/4GB/xMVEkxPhIiPERH+sjPtpHQmzweXBZ8fwYn2Fmkf5nqJQCXCQMnHMUFjnyC4so8BeR7y8KTrvA88LAvILiR38R+YWuZN6Z6wTmubO2c/qxwO/IK5k+Pb94XnGwFp0RcqWCNzjfnTG/OFSLx9b1rwnwRVlJsMcXh/4Z4Z9w1vzi6YTYqFLPz5zfpUVjEmJ9Ya1TAS51hnOB4DuZ7+dkfiGn8v3BaT+nCgpLpk/mFXKywF96eX5hcFwZ8/L9nCzw4y8Kb+r5oowYnxHjiyIuOooYX+AnNvr0Y6zPiI2OokF8dGCeL4ponxFlhhlEmRFlgW1ZcDowz0qWRUUFxvrOmGdm+KJOT5e/ncD6pdYL7tsXnF+8nZLpKDu9r6jAfou36yteFnV6/aiz5p/e5hnbDi73RZWuFSDfX0RuQRG5wX/T3MLA46kCP3kFRZwqOP08N/gTmA4syz1rnSOnCth71F+yXm5wbL6/qMJ/z49+cR2XX9IgrP+NKMDFk5xz5Bw6xbItB9iw+xgng2F6Iu90GJ8dwKcK/FQlY80gIcZHvdjAR+16MdGBx1gfTevFUi/2jGXBj96lwzWKmGgj1hf4SB4THUWcL4qY4jG+KGKLl0db6fV8USUBJBcmLtpHXLSPxgkx1boff5ErCf9T+X7yCv2cyg/+gijw07JJfNj3qQAXT3DOse3ASZZvOcDyrQdZvuUA3x7JBSA+JoqG8TGBMA0Gbv3YaJo3iDsdsjHRgek4H/VifNSLPR3GgcfoUuvXi40mPibKE+dBpXbwRRn146KpH1dzsaoAl1rJOcfmfcdZtuUgy7ce5IutB9hzNA+AxPqxpLdrxv1tE0lv14yOlzQkSkerUgcpwKVWKCpyfLX3GMu3HGT51gN8sfUg+4/nA3BJwzjS2yWS3rYZfdo1o31SAx0Zi6AAlwgpKnKs3320VGAfOlkAQMvG8fxHhyTS2zYjvV0iKYn1FNgiZVCAS40o9BexblfpwD6aWwhAm2YJDOycHDzCTqR10wQFtkgIFOBSLQr8RWTvPFIS2BnbDnE8LxDYKYn1GHxlC9LbBY6wWzVJiHC1It4UUoCbWRPgr8CVgAPGABuBOUAKsA24wzl3qFqqlFovr9DP6pwjJVeJZG4/xMl8PwDtk+pzS4+WJUfYyY3CfzmVSF0U6hH4C8D7zrnbzCwWqAc8Dix2zj1nZhOBicCEaqpTIqjAX1Rys0Jeob/kpojDJwvI2H6Q5VsOsuKbQ+QVBm5kuCK5Ibf1bk1620SuatuMpIZxEX4FIhenSgPczBoD1wL3ATjn8oF8MxsG9A8OmwV8ggK8RuQV+jmWW1gSqrkF/pJgPTNgSx4LA3eclTwW+M8N5OL1g8vyCovXLarwDkMz6HxpI36YfllJYDerH1uD74ZI3RXKEXhbYB/wqpl1BzKBh4Bk59yu4JjdQHJZK5vZOGAcwGWXXXbBBddlp/L9TP90Cy//72ZOFfirvH5sdBTx0ad7NcTHRBEXHXhsEBdNYv3TvR/iSsZFER9denxccEyDuGiubNmYxvWq9w43ESlbKAEeDfQCxjvnlpvZCwROl5RwzjkzK/MwzTk3HZgOkJaWVsdb5Jwf5xzvZu/i2X9uYOfhU9zU9VL6tEsk/owwjY/xER8dFey8Vjp042N8xPqidLOLyEUmlADPAXKcc8uDz+cRCPA9ZtbCObfLzFoAe6uryLpszc4j/GbROr7YdpAuLRrx/B3dSW+XGOmyRKQWqDTAnXO7zWyHmV3hnNsIDATWBX9GAc8FHxdUa6V1zP7jefzXBxuZ/eUOmtaL5dkfdOWOtDZqcCQiJUK9CmU88EbwCpQtwGgC3+Yz18zGAtuBO6qnxLolv7CI15Zu44WPNnGqwM/Yvm0ZP7BDtXdSExHvCSnAnXNZQFoZiwaGt5y6bcmGvTz9zjq27D/B9Vck8cTQLrRPCm//YBG5eOhOzFrg673HePqd9fzvV/tol1SfV+/7Ltd3uiTSZYlILacAj6AjJwt4YfEmXlu6jYRYH08M6cy9V6cQG63vmhaRyinAI8Bf5Jj95Tf81wdfcehkPndddRmP3tCRxAa6Y1FEQqcAr2FLNx/g14vWsmH3MdLbNuNXN3chtWXjSJclIh6kAK8hOw6e5Jl/rue9Nbtp1SSB//lRLwZfeanaporIeVOAV7MTeYX86ZPNTP9sCz4zHr2hIz+5th3xMb5IlyYiHqcAryZFRY4Fq3by3Hsb2HM0j+E9WjJhcCdaNFbvaxEJDwV4NcjacZhfL1rLym8O0611Y/7nR73o/Z1mkS5LRC4yCvAw2ns0lynvb+TtFTkkNYxj6u3d+UHPVmoiJSLVQgEeBrkFfl7511b+Z8nXFPgdD/Rvz8+uv5wGcXp7RaT6KGEugHOO/7d2D7/95zp2HDzFjV2SmTSkM99JrB/p0kSkDlCAn6cNu4/ym0Xr+PfmA3RMbsDfxqbTr0PzSJclInWIAryKDp3I5/kPv+KN5dtplBDD08NSueuqy4j26fZ3EalZCvAQOed464sdTHl/A8fzCrn36hQe/l4HmtTT9z+KSGQowENQ6C/iN++s47Wl27mmfSJP3ZJKx+SGkS5LROo4BXglTuQV8vO3VrJ4w17uv7YdEwZ10mWBIlIrKMArsPdoLmNmfcm6b4/y9PAruafPdyJdkohICQV4Ob7ac4zRr37JoZP5vDJKX7AgIrWPArwMn3+9n5++nklCrI+591/Nla3U7lVEah8F+Fn+b8YOHvt7Nu2TGvDq6O/SsomaT4lI7aQAD3LOMe2jTby4eBP/0aE5//2jXjSK1zfBi0jtpQAH8guLmPj2av6+cie3927NMz/oSoxuzBGRWq7OB/iRkwXc/7cMlm05yKM3dOTBAZfrW3JExBPqdIDvOHiS0TO/ZPuBE0y7szsjeraOdEkiIiGrswG+OucwY2ZmkF/o5/Wx6fRplxjpkkREqqROBviH6/bw87dWktggltnj0rn8Et0WLyLeU+cCfObnW/n1O+vo1roJf703jaSGcZEuSUTkvIQU4Ga2DTgG+IFC51yamTUD5gApwDbgDufcoeop88L5ixy/fXc9Mz7fyo1dknlhZE8SYvXN8CLiXVW5Vu5651wP51xa8PlEYLFzrgOwOPi8VjqV7+eBv2Uy4/OtjO6bwp/u7q3wFhHPu5BTKMOA/sHpWcAnwIQLrCfs9h3L48evZbA65zC/GtqFMf3aRrokEZGwCDXAHfCBmTngz8656UCyc25XcPluILk6CrwQX+89zuiZX7DvWB5/vrs3N6ZeGumSRETCJtQA7+ec22lmlwAfmtmGMxc651ww3M9hZuOAcQCXXXbZBRVbFcu2HGDcaxnERkcxZ9zVdG/TpMb2LSJSE0I6B+6c2xl83AvMB64C9phZC4Dg495y1p3unEtzzqUlJSWFp+pKLMjayb2vfMEljeKZ/3/6KrxF5KJUaYCbWX0za1g8DdwIrAEWAqOCw0YBC6qryFA553jp4008NDuLXt9pwts/vYY2zepFuiwRkWoRyimUZGB+sD9INPCmc+59M/sSmGtmY4HtwB3VV2blCvxFTJqfzdyMHEb0bMVzt3YlLlpXmojIxavSAHfObQG6lzH/ADCwOoqqqqO5BfzsjRV8tmk/Px9wOY/c0FENqUTkouf5OzG/PXyKMTO/5Ou9x/ndbd24I61NpEsSEakRng7wNTuPMGbml5zK9zNz9FX069A80iWJiNQYzwb4kg17+dmbK2iSEMO8B67hikvVkEpE6hZPBvjflm3nVwvW0KVlI14Z9V2SG8VHuiQRkRrnqQAvKnJMeX8Df/50CwM6XcIf7+pJ/ThPvQQRkbDxTPrlFvh5dO4q3s3exd19LuOpm1OJ1vdWikgd5okAP3gin5+8lkHm9kM8flMnfvIf7XSZoIjUebU+wJ1z3P96Btk7j/DfP+zFkG4tIl2SiEitUOsD3Mx4YkgXCouK6P2dZpEuR0Sk1qj1AQ6oGZWISBn0V0AREY9SgIuIeJQnTqGISPgVFBSQk5NDbm5upEuRoPj4eFq3bk1MTExI4xXgInVUTk4ODRs2JCUlRZfl1gLOOQ4cOEBOTg5t24b23b06hSJSR+Xm5pKYmKjwriXMjMTExCp9IlKAi9RhCu/apar/HgpwERGPUoCLiHiUAlxEImr37t2MHDmS9u3b07t3b2666Sa++uorzIw//vGPJeMefPBBZs6cCcB9991Hq1atyMvLA2D//v2kpKRUuB+fz0ePHj3o0aMHt9xyS1hfQ//+/cnIyADgpptu4vDhw+eMeeqpp5g6dWpY96urUESEXy9ay7pvj4Z1m11aNuLJm1MrHOOcY8SIEYwaNYrZs2cDsGrVKvbs2cMll1zCCy+8wP33309sbOw56/p8PmbMmMEDDzwQUj0JCQlkZWVV/YVU0T//+c9q30cxHYGLSMQsWbKEmJgYfvrTn5bM6969O23atCEpKYmBAwcya9asMtd9+OGHmTZtGoWFhWGt6f333+f2228vef7JJ58wdOhQAB544AHS0tJITU3lySefLHP9lJQU9u/fD8Bvf/tbOnbsSL9+/di4cWNY6wQdgYsIVHqkXF3WrFlD7969y10+YcIEBg8ezJgxY85Zdtlll9GvXz9ef/11br755kr3lZubS1paGtHR0UycOJHhw4eXOe573/se48aN48SJE9SvX585c+YwcuRIIBDIzZo1w+/3M3DgQFavXk23bt3K3E5mZiazZ88mKyuLwsJCevXqVeFrPR86AheRWqtdu3akp6fz5ptvlrn8scce4/e//z1FRUWVbmv79u1kZGTw5ptv8vDDD7N58+Yyx0VHRzNo0CAWLVpEYWEh7777LsOGDQNg7ty59OrVi549e7J27VrWrVtX7v4+++wzRowYQb169WjUqFHYz7uDAlxEIig1NZXMzMwKxzz++ONMmTIF59w5yzp06ECPHj2YO3dupftq1aoVEPil0L9/f1auXFnu2JEjRzJ37lw+/vhj0tLSaNiwIVu3bmXq1KksXryY1atXM2TIkIi3IVCAi0jEDBgwgLy8PKZPn14yb/Xq1ezYsaPkeadOnejSpQuLFi0qcxuTJk2q9OqOQ4cOlbpi5fPPP6dLly7ljr/uuutYsWIFf/nLX0pOnxw9epT69evTuHFj9uzZw3vvvVfhPq+99lr+8Y9/cOrUKY4dO1Zu/RdCAS4iEWNmzJ8/n48++oj27duTmprKY489xqWXXlpq3KRJk8jJySlzG6mpqfTq1avC/axfv560tDS6d+/O9ddfz8SJEysMcJ/Px9ChQ3nvvfdK/oDZvXt3evbsSadOnfjhD39I3759K9xnr169uPPOO+nevTuDBw/mu9/9boXjz4eV9bGkuqSlpbniayVFJLLWr19P586dI12GnKWsfxczy3TOpZ09VkfgIiIeFfJlhGbmAzKAnc65oWbWFpgNJAKZwD3OufzqKVNEpHLZ2dncc889pebFxcWxfPnyMsePGDGCrVu3lpo3ZcoUvv/971dbjeFUlevAHwLWA42Cz6cA05xzs83sZWAs8Kcw1yciErKuXbtW6W7L+fPnV2M11S+kUyhm1hoYAvw1+NyAAcC84JBZQNlXxYuISLUI9Rz4H4D/BIqvlk8EDjvniu9hzQFalbWimY0zswwzy9i3b98FFSsiIqdVGuBmNhTY65yr+Gr7cjjnpjvn0pxzaUlJSeezCRERKUMoR+B9gVvMbBuBP1oOAF4AmphZ8Tn01sDOaqlQRC5qF0M72UipNMCdc48551o751KAkcDHzrkfAUuA24LDRgELqq1KEbkoFbeT7d+/P5s3byYzM5Nnn322VDvZ/PyyL24rbicbquJ2sllZWSxcuDBcLyGiLqQb4QRgtplNBlYCr4SnJBGpce9NhN3Z4d3mpV1h8HMVDimvney2bdtISkqib9++zJo1i5/85CfnrFvcTrasZRdq4sSJLFy4kOjoaG688UamTp3KokWLmDx5Mvn5+SQmJvLGG2+QnJzMU089xdatW9myZQvffPMN06ZNY9myZbz33nu0atWKRYsWERMTQ2ZmJr/4xS84fvw4zZs3Z+bMmbRo0eKC6qzSjTzOuU+cc0OD01ucc1c55y53zt3unMu7oEpEpM4JpZ3s1KlT8fv95yw7s51sKIrbyfbp04d//OMf5Y47cOAA8+fPZ+3ataxevZonnngCgH79+rFs2TJWrlzJyJEj+d3vfleyzubNm/n4449ZuHAhd999N9dffz3Z2dkkJCTw7rvvUlBQwPjx45k3bx6ZmZmMGTOGSZMmhVR3RdQPXEQqPVKOlFDayQ4bNowhQ4ZUuq3t27fTqlUrtmzZwoABA+jatSvt27c/Z1zjxo2Jj49n7NixDB06tKQXSk5ODnfeeSe7du0iPz+ftm3blqwzePBgYmJi6Nq1K36/n0GDBgGB69K3bdvGxo0bWbNmDTfccAMAfr//go++QbfSi0gE1cZ2stHR0XzxxRfcdtttvPPOOyVhPH78eB588EGys7P585//XKqVbFxcHABRUVHExMQQuFUm8LywsBDnHKmpqSXn4LOzs/nggw8qrbkyCnARiZja2E72+PHjHDlyhJtuuolp06axatUqAI4cOVLyS6C8r3krzxVXXMG+fftYunQpAAUFBaxdu7ZK2yiLAlxEIqY2tpM9duwYQ4cOpVu3bvTr14/nn38eCHyr/O23307v3r1p3rx5lV5nbGws8+bNY8KECXTv3p0ePXrw73//u0rbKIvayYrUUWonWzupnayISB2gq1BE5KKhdrIiIh6ldrIiIuIJCnAREY9SgIuIeJQCXETEoxTgIhJRNdEPfPv27fTq1YsePXqQmprKyy+/HNbXkJKSwv79+wG45ppryhxz3333MW/evDKXnS8FuIhETE31A2/RogVLly4lKyuL5cuX89xzz/Htt9+G86WUCMcdlqHSZYQiwpQvprDh4IawbrNTs05MuGpChWNqqh94bGxsyXReXh5FRUXljn355ZfZvHkzv//97wGYOXMmGRkZvPTSSwwfPpwdO3aQm5vLQw89xLhx485Zv0GDBhw/fhznHOPHj+fDDz+kTZs2pWoIFx2Bi0jE1GQ/8B07dtCtWzfatGnDhAkTaNmyZZnjbr311lLXh8+ZM4eRI0cCMGPGDDIzM8nIyODFF1/kwIED5e5v/vz5bNy4kXXr1vHaa69Vy5G5jsBFpNIj5UgJZz/wNm3asHr1ar799luGDx/ObbfdRnJy8jnjkpKSaNeuHcuWLaNDhw5s2LCBvn37AvDiiy+WhPuOHTvYtGkTiYmJZe7v008/5a677sLn89GyZUsGDBgQ6ssOmY7ARSRiarIfeLGWLVty5ZVX8tlnn5U7ZuTIkcydO5e3336bESNGYGZ88sknfPTRRyxdupRVq1bRs2fPUj3BI0EBLiIRU1P9wHNycjh16hQQ6A3+r3/9iyuuuKLc8SNGjGDBggW89dZbJadPjhw5QtOmTalXrx4bNmxg2bJlFe7z2muvZc6cOfj9fnbt2sWSJUsqHH8+FOAiEjE12Q88PT2d7t27c9111/HLX/6Srl27lju+adOmdO7cme3bt3PVVVcBMGjQIAoLC+ncuTMTJ06kT58+Fe5zxIgRdOjQgS5dunDvvfdy9dVXVzj+fKgfuEgdpX7gtZP6gYuI1AG6CkVELhpV7Qeenp5ecjdnsddff73C0yu1iQJcRC4aVe0HXl6we4VOoYiIeJQCXETEoxTgIiIeVWmAm1m8mX1hZqvMbK2Z/To4v62ZLTezr81sjpmFv1OLiIiUK5Qj8DxggHOuO9ADGGRmfYApwDTn3OXAIWBs9ZUpIheri6EfeKRUGuAu4HjwaUzwxwEDgOLu5LOA4dVSoYhctC7GfuA1KaTLCM3MB2QClwP/DWwGDjvnCoNDcoBW1VKhiFS73c88Q9768PYDj+vciUsff7zCMbWxH7jf72fs2LFkZGRgZowZM4ZHHnmEv/zlL0yfPp38/Hwuv/xyXn/9derVq8d9991HQkICK1euZO/evcyYMYPXXnuNpUuXkp6eXvKp4YMPPuDJJ58kLy+P9u3b8+qrr9KgQYNKa69ISH/EdM75nXM9gNbAVUCnUHdgZuPMLMPMMvbt23eeZYrIxag29gPPyspi586drFmzhuzsbEaPHg3AD37wA7788ktWrVpF586deeWVV0rWOXToEEuXLmXatGnccsstPPLII6xdu5bs7GyysrLYv38/kydP5qOPPmLFihWkpaXx/PPPh1R3Rap0I49z7rCZLQGuBpqYWXTwKLw1sLOcdaYD0yHQC+UC6xWRalDZkXKkRKIfeLt27diyZQvjx49nyJAh3HjjjUDgl80TTzzB4cOHOX78ON///vdL1rn55psxM7p27UpycnLJnZypqals27aNnJwc1q1bV9JXPD8/PyzNrUK5CiXJzJoEpxOAG4D1wBLgtuCwUcCCC65GROqU2tgPvGnTpqxatYr+/fvz8ssv8+Mf/xgI/OH0pZdeIjs7myeffLJUL/C4uDgAoqKiSqaLnxcWFuKc44YbbiArK4usrCzWrVtX6gj+fIVyCqUFsMTMVgNfAh86594BJgC/MLOvgUTgwqsRkTqlNvYD379/P0VFRdx6661MnjyZFStWAHDs2DFatGhBQUEBb7zxRpVeZ58+ffj888/5+uuvAThx4gRfffVVlbZRlkpPoTjnVgM9y5i/hcD5cBGR81LcD/zhhx9mypQpxMfHk5KSwh/+8IdS4yZNmkTPnufEEHC6H3hx0JZl/fr1PProo5gZzrkK+4Hv3LmT0aNHl/yh89lnnwXg6aefJj09naSkJNLT0zl27FjIrzMpKYmZM2dy1113lVz6OHnyZDp27BjyNsqifuAidZT6gddO6gcuIlIHqJ2siFw01A9cROoM5xxmFukywsbr/cCrekpbp1BE6qj4+HgOHDhQ5dCQ6uGc48CBA8THx4e8jo7AReqo1q1bk5OTg+6Qrj3i4+Np3bp1yOMV4CJ1VExMDG3bto10GXIBdApFRMSjFOAiIh6lABcR8SgFuIiIRynARUQ8SgEuIuJRCnAREY9SgIuIeJQCXETEoxTgIiIepQAXEfEoBbiIiEcpwEVEPEoBLiLiUQpwERGPUoCLiHiUAlxExKMU4CIiHqUAFxHxKAW4iIhHKcBFRDyq0gA3szZmtsTM1pnZWjN7KDi/mZl9aGabgo9Nq79cEREpFsoReCHwqHOuC9AH+JmZdQEmAoudcx2AxcHnIiJSQyoNcOfcLufciuD0MWA90AoYBswKDpsFDK+uIkVE5FxVOgduZilAT2A5kOyc2xVctBtILmedcWaWYWYZ+/btu4BSRUTkTCEHuJk1AN4GHnbOHT1zmXPOAa6s9Zxz051zac65tKSkpAsqVkRETgspwM0shkB4v+Gc+3tw9h4zaxFc3gLYWz0liohIWUK5CsWAV4D1zrnnz1i0EBgVnB4FLAh/eSIiUp7oEMb0Be4Bss0sKzjvceA5YK6ZjQW2A3dUT4kiIlKWSgPcOfcvwMpZPDC85YiISKh0J6aIiEcpwEVEPEoBLiLiUQpwERGPUoCLiHiUAlxExKMU4CIiHqUAFxHxKAW4iIhHKcBFRDxKAS4i4lEKcBERj1KAi4h4lAJcRMSjFOAiIh6lABcR8SgFuIiIRynARUQ8SgEuIuJRCnAREY9SgIuIeJQCXETEoxTgIiIepQAXEfEoBbiIiEcpwEVEPEoBLiLiUQpwERGPqjTAzWyGme01szVnzGtmZh+a2abgY9PqLVNERM4WyhH4TGDQWfMmAoudcx2AxcHnIiJSg6IrG+Cc+9TMUs6aPQzoH5yeBXwCTAhjXaVMmXszG07uqq7Ni4hUq071WjDhjkVh3+75ngNPds4VJ+puILm8gWY2zswyzCxj375957k7ERE5W6VH4JVxzjkzcxUsnw5MB0hLSyt3XEWq4zeXiIjXnW+A7zGzFs65XWbWAtgbzqLOtvuZZ8hbv6E6dyEiUm3iOnfi0scfD/t2z/cUykJgVHB6FLAgPOWIiEioKj0CN7O3CPzBsrmZ5QBPAs8Bc81sLLAduKM6i6yO31wiIl4XylUod5WzaGCYaxERkSrQnZgiIh6lABcR8SgFuIiIRynARUQ8SgEuIuJRCnAREY9SgIuIeJQ5d17tSc5vZ2b7CNz442XNgf2RLqKW0HtRmt6P0vR+nHah78V3nHNJZ8+s0QC/GJhZhnMuLdJ11AZ6L0rT+1Ga3o/Tquu90CkUERGPUoCLiHiUArzqpke6gFpE70Vpej9K0/txWrW8FzoHLiLiUToCFxHxKAW4iIhHKcBDYGZtzGyJma0zs7Vm9lCka6oNzMxnZivN7J1I1xJpZtbEzOaZ2QYzW29mV0e6pkgxs0eC/5+sMbO3zCw+0jXVJDObYWZ7zWzNGfOamdmHZrYp+Ng0HPtSgIemEHjUOdcF6AP8zMy6RLim2uAhYH2ki6glXgDed851ArpTR98XM2sF/BxIcwEljqEAAAIKSURBVM5dCfiAkZGtqsbNBAadNW8isNg51wFYHHx+wRTgIXDO7XLOrQhOHyPwP2eryFYVWWbWGhgC/DXStUSamTUGrgVeAXDO5TvnDke2qoiKBhLMLBqoB3wb4XpqlHPuU+DgWbOHAbOC07OA4eHYlwK8iswsBegJLI9sJRH3B+A/gaJIF1ILtAX2Aa8GTyn91czqR7qoSHDO7QSmAt8Au4AjzrkPIltVrZDsnNsVnN4NJIdjowrwKjCzBsDbwMPOuaORridSzGwosNc5lxnpWmqJaKAX8CfnXE/gBGH6iOw1wXO7wwj8UmsJ1DezuyNbVe3iAtduh+X6bQV4iMwshkB4v+Gc+3uk64mwvsAtZrYNmA0MMLO/RbakiMoBcpxzxZ/K5hEI9Lroe8BW59w+51wB8HfgmgjXVBvsMbMWAMHHveHYqAI8BGZmBM5vrnfOPR/peiLNOfeYc661cy6FwB+oPnbO1dmjLOfcbmCHmV0RnDUQWBfBkiLpG6CPmdUL/n8zkDr6B92zLARGBadHAQvCsVEFeGj6AvcQONLMCv7cFOmipFYZD7xhZquBHsAzEa4nIoKfQuYBK4BsAhlTp26pN7O3gKXAFWaWY2ZjgeeAG8xsE4FPKc+FZV+6lV5ExJt0BC4i4lEKcBERj1KAi4h4lAJcRMSjFOAiIh6lABcR8SgFuIiIR/1/SbzUZVAr4FcAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5ovuSCAMRJaB"
      },
      "source": [
        "#Additional code to explore the dataset and the trained model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xPDRDas64btL"
      },
      "source": [
        "# Show some random training images\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # unnormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "    \n",
        "# get some random training images\n",
        "dataiter = iter(trainloader)\n",
        "images, labels = dataiter.next()\n",
        "print(images.size())\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join('%5s' % classes[labels[j]] for j in range(4)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmQoiOSz46E2"
      },
      "source": [
        "# Test the network on some test images\n",
        "\n",
        "dataiter = iter(testloader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# print images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "print('GroundTruth: ', ' '.join('%5s' % classes[labels[j]] for j in range(4)))\n",
        "\n",
        "# The outputs are energies for the 10 classes.\n",
        "# The higher the energy for a class, the more the network\n",
        "# thinks that the image is of the particular class.\n",
        "# So, let's get the index of the highest energy:\n",
        "outputs = net(images)\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted: ', ' '.join('%5s' % classes[predicted[j]]\n",
        "                              for j in range(4)))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aT8hcwhg5H7W"
      },
      "source": [
        "# Lets check what are the classes that performed well, and the classes that did\n",
        "# not perform well:\n",
        "\n",
        "class_correct = list(0. for i in range(10))\n",
        "class_total = list(0. for i in range(10))\n",
        "with torch.no_grad():\n",
        "    for images, labels in testloader:\n",
        "        if CUDA:\n",
        "          images =images.cuda()\n",
        "          labels =labels.cuda()\n",
        "        else:\n",
        "          images =images.cpu()\n",
        "          labels =labels.cpu()     \n",
        "      \n",
        "        outputs = net(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        c = (predicted == labels).squeeze()\n",
        "        for i in range(4):\n",
        "            label = labels[i]\n",
        "            class_correct[label] += c[i].item()\n",
        "            class_total[label] += 1\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('Accuracy of %5s : %2d %%' % (\n",
        "        classes[i], 100 * class_correct[i] / class_total[i]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdiZ2QrMTsA9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}